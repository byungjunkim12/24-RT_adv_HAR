{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from GAIL.models.nets import Expert\n",
    "from GAIL.models.gail import GAIL\n",
    "\n",
    "from utilities import *\n",
    "from utilitiesDL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity: fall trExpDataset: 93 trAgentDataset: 39 tsDataset: 311\n",
      "activity: pickup trExpDataset: 103 trAgentDataset: 45 tsDataset: 347\n",
      "activity: run trExpDataset: 253 trAgentDataset: 109 tsDataset: 847\n",
      "activity: sitdown trExpDataset: 86 trAgentDataset: 37 tsDataset: 289\n",
      "activity: standup trExpDataset: 64 trAgentDataset: 27 tsDataset: 214\n",
      "activity: walk trExpDataset: 307 trAgentDataset: 132 tsDataset: 1026\n",
      "trExpLoader: 227 trAgentLoader 98 tsLoader: 304\n"
     ]
    }
   ],
   "source": [
    "DataFGMDir = '/project/iarpa/wifiHAR/HAR_survey/window_FGM/'\n",
    "LSTMModelDir = './savedModels/selected/'\n",
    "\n",
    "GAILModelJsonFileName = './GAIL/GAILModelConfig.json'\n",
    "GAILModelJson = json.load(open(GAILModelJsonFileName))\n",
    "\n",
    "GAILJsonFileName = './inputJson/GAIL/test.json'\n",
    "GAILJson = json.load(open(GAILJsonFileName))\n",
    "\n",
    "LSTMModelName = GAILJson['LSTMModelName']\n",
    "noiseAmpRatio = GAILJson['noiseAmpRatio']\n",
    "trDataRatio = GAILJson['trDataRatio']\n",
    "trExpDataRatio = GAILJson['trExpDataRatio']\n",
    "cudaID = GAILJson['cudaID']\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "if cudaID >= 0:\n",
    "    device = torch.device(\"cuda:\"+str(cudaID))\n",
    "    cudaAvbl = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    cudaAvbl = False\n",
    "\n",
    "dataType = LSTMModelName.split('_')[0]\n",
    "\n",
    "if dataType == 'survey':\n",
    "    fs = 1000 # 1 kHz\n",
    "    nSubC = 30\n",
    "    nRX = 3\n",
    "    \n",
    "    winLen = 1000\n",
    "    thres = 60\n",
    "    slideLen = 400\n",
    "    activities = ['fall', 'pickup', 'run', 'sitdown', 'standup', 'walk']\n",
    "\n",
    "LSTMType = LSTMModelName.split('_')[1]\n",
    "bidirectional = (LSTMType == 'BLSTM')\n",
    "nHidden = int(LSTMModelName.split('_')[3])\n",
    "threshold = int(LSTMModelName.split('_')[5])\n",
    "nLayer = int(LSTMModelName.split('_')[7])\n",
    "\n",
    "# Load the LSTM model\n",
    "HARNet = LSTMNet(nClasses=len(activities), input_size=nSubC*nRX, bidirectional=bidirectional,\\\n",
    "                hidden_size=nHidden, num_layers=1, seq_length=winLen//2, device=device)\n",
    "HARNet.load_state_dict(torch.load(LSTMModelDir + LSTMModelName + '.cpkt'))\n",
    "HARNet.to(device)\n",
    "\n",
    "# Load dataset labelled with FGM attack\n",
    "FGMdatasetDir = '/project/iarpa/wifiHAR/HAR_' + dataType + '/window_FGM/'\n",
    "dataDict = {file:[] for file in activities}\n",
    "tsDataDict = {file:[] for file in activities}\n",
    "\n",
    "trExpDataset = list()\n",
    "trAgentDataset = list()\n",
    "# trDataset = list()\n",
    "tsDataset = list()\n",
    "for actInd, activity in enumerate(activities):\n",
    "    dataDict[activity] = defaultdict(list)\n",
    "\n",
    "    dataActFileName = FGMdatasetDir + LSTMModelName + '_' + activity + '.pt'\n",
    "    dataAct = torch.load(dataActFileName)\n",
    "\n",
    "    dataDict[activity]['obs'] =\\\n",
    "        torch.reshape(torch.squeeze(dataAct[0, :, :]), (-1, winLen//2, nSubC*nRX)).detach().cpu().numpy()\n",
    "    dataDict[activity]['FGM'] = noiseAmpRatio *\\\n",
    "        torch.reshape(torch.squeeze(torch.squeeze(dataAct[1, :, :])),\\\n",
    "                      (-1, winLen//2, nSubC*nRX)).detach().cpu().numpy()\n",
    "    dataDict[activity]['label'] =\\\n",
    "        actInd * np.ones((dataDict[activity]['obs'].shape[0]), dtype=int)\n",
    "\n",
    "    datasetAct = FGMDataset(dataDict[activity], device)\n",
    "\n",
    "    trExpDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                                range(int(trDataRatio*trExpDataRatio*len(datasetAct)))))\n",
    "    trAgentDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                                  range(int(trDataRatio*trExpDataRatio*len(datasetAct)),\\\n",
    "                                                        int(trDataRatio*len(datasetAct)))))\n",
    "    # trDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "    #                                         range(int(trDataRatio*len(datasetAct)))))\n",
    "    tsDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                             range(int(trDataRatio*len(datasetAct)), len(datasetAct))))\n",
    "\n",
    "    # print('activity:', activity, 'trDataset:', len(trDataset[-1]), 'tsDataset:', len(tsDataset[-1]))\n",
    "    print('activity:', activity, 'trExpDataset:', len(trExpDataset[-1]),\\\n",
    "          'trAgentDataset:', len(trAgentDataset[-1]), 'tsDataset:', len(tsDataset[-1]))\n",
    "\n",
    "\n",
    "trExpLoader = DataLoader(torch.utils.data.ConcatDataset(trExpDataset),\\\n",
    "                      batch_size=4, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "trAgentLoader = DataLoader(torch.utils.data.ConcatDataset(trAgentDataset),\\\n",
    "                      batch_size=4, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "# trLoader = DataLoader(torch.utils.data.ConcatDataset(trDataset),\\\n",
    "#                       batch_size=4, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "tsLoader = DataLoader(torch.utils.data.ConcatDataset(tsDataset),\\\n",
    "                      batch_size=10, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "\n",
    "# print('trExpLoader:', len(trLoader), 'tsLoader:', len(tsLoader))\n",
    "print('trExpLoader:', len(trExpLoader), 'trAgentLoader', len(trAgentLoader), 'tsLoader:', len(tsLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.nn import Module\n",
    "\n",
    "from GAIL.models.nets import PolicyNetwork, ValueNetwork, Discriminator\n",
    "from GAIL.utils.funcs import get_flat_grads, get_flat_params, set_params, \\\n",
    "    conjugate_gradient, rescale_and_linesearch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    from torch import FloatTensor\n",
    "\n",
    "\n",
    "class GAIL(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        discrete,\n",
    "        device,\n",
    "        train_config=None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.discrete = discrete\n",
    "        self.device = device\n",
    "        self.train_config = train_config\n",
    "\n",
    "        self.pi = PolicyNetwork(self.state_dim, self.action_dim, self.discrete, self.device)\n",
    "        self.v = ValueNetwork(self.state_dim, self.device)\n",
    "        self.d = Discriminator(self.state_dim, self.action_dim, self.discrete, self.device)\n",
    "\n",
    "    def get_networks(self):\n",
    "        return [self.pi, self.v]\n",
    "\n",
    "    def act(self, state):\n",
    "        self.pi.eval()\n",
    "\n",
    "        state = FloatTensor(state)\n",
    "        distb = self.pi(state)\n",
    "\n",
    "        action = distb.sample().detach().cpu().numpy()\n",
    "\n",
    "        return action\n",
    "\n",
    "    def train(self, HARNet, trExpLoader, trAgentLoader, tsLoader, render=False):\n",
    "        num_iters = self.train_config[\"num_iters\"]\n",
    "        num_steps_per_iter = self.train_config[\"num_steps_per_iter\"]\n",
    "        horizon = self.train_config[\"horizon\"]\n",
    "        lambda_ = self.train_config[\"lambda\"]\n",
    "        gae_gamma = self.train_config[\"gae_gamma\"]\n",
    "        gae_lambda = self.train_config[\"gae_lambda\"]\n",
    "        eps = self.train_config[\"epsilon\"]\n",
    "        max_kl = self.train_config[\"max_kl\"]\n",
    "        cg_damping = self.train_config[\"cg_damping\"]\n",
    "        normalize_advantage = self.train_config[\"normalize_advantage\"]\n",
    "\n",
    "        opt_d = torch.optim.Adam(self.d.parameters())\n",
    "\n",
    "        noiseAmpRatioList = [1e-4, 1e-3, 1e-2, 0.1]\n",
    "        # noiseAmpRatioList = [1e-5]\n",
    "        # noiseAmpRatioList = [1e-10]\n",
    "        print('----White-box attack performance (Expert)----')\n",
    "        lineBreakCount = 0\n",
    "        print('[ampRatio, Acc.]:', end=' ')\n",
    "        for noiseAmpRatio in noiseAmpRatioList:\n",
    "            nData = 0.\n",
    "            correct = 0.\n",
    "            for tsBatch in tsLoader:\n",
    "                pred_l,label_l = getPredsGAIL(tsBatch['obs'], tsBatch['FGM'], tsBatch['label'],\\\n",
    "                                              HARNet, noiseAmpRatio)\n",
    "                nData += len(label_l)\n",
    "                for pred, label in zip(pred_l, label_l):\n",
    "                    correct += (pred == label)\n",
    "                # accuracyList.append(correct/nData)\n",
    "            print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nData), end=' ')\n",
    "            lineBreakCount += 1\n",
    "            if lineBreakCount == 4:\n",
    "                print('')\n",
    "                lineBreakCount = 0\n",
    "\n",
    "        exp_obs = []\n",
    "        exp_acts = []\n",
    "        exp_acc_iter = []\n",
    "\n",
    "        for trExpBatch in trExpLoader:\n",
    "            exp_ob = trExpBatch['obs'].transpose(0, 1).reshape(-1, trExpBatch['obs'].shape[2])\n",
    "            exp_act = trExpBatch['FGM'].transpose(0, 1).reshape(-1, trExpBatch['FGM'].shape[2])\n",
    "            \n",
    "            exp_obs.append(exp_ob)\n",
    "            exp_acts.append(exp_act)\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            if lineBreakCount != 0:\n",
    "                print('')\n",
    "            print('----Iteratons: {}----'.format(i))\n",
    "            obs = []\n",
    "            acts = []\n",
    "            rets = []\n",
    "            advs = []\n",
    "            gms = []\n",
    "            \n",
    "            nData = 0\n",
    "            correct = [0. for _ in noiseAmpRatioList]\n",
    "            for trAgentBatch in trAgentLoader:\n",
    "                nData += trAgentBatch['obs'].shape[0]\n",
    "                seqLength = trAgentBatch['obs'].shape[1]\n",
    "                # print('obs amp:', LA.norm(trAgentData['obs'].view(trAgentData['obs'].shape[0], -1), dim=1))\n",
    "                obsAmp = LA.norm(trAgentBatch['obs'].view(trAgentBatch['obs'].shape[0], -1), dim=1)\n",
    "                ob = trAgentBatch['obs'].transpose(0, 1).reshape(-1, trAgentBatch['obs'].shape[2])\n",
    "                act = self.act(ob)\n",
    "                actTorch = torch.reshape(torch.from_numpy(act), ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)\n",
    "                \n",
    "                lineBreakCount = 0\n",
    "                for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "                    # print(trAgentBatch['obs'].shape, actTorch.shape, trAgentBatch['FGM'].shape)\n",
    "                    pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], actTorch, trAgentBatch['label'],\\\n",
    "                                                    HARNet, noiseAmpRatio)\n",
    "\n",
    "                    # print(pred_l, label_l)\n",
    "                    for pred, label in zip(pred_l, label_l):\n",
    "                        correct[noiseAmpIndex] += (pred == label)\n",
    "                        # print(correct)\n",
    "                    \n",
    "                obs.append(ob)\n",
    "                acts.append(act)\n",
    "\n",
    "                for i, trAgentData in enumerate(trAgentBatch['obs']):\n",
    "                    ep_obs = trAgentData\n",
    "                    ep_acts = FloatTensor(act[i*seqLength : (i+1)*seqLength]).to(device)\n",
    "                    ep_gms = torch.pow(gae_gamma, torch.arange(seqLength)).to(device)\n",
    "                    ep_lmbs = torch.pow(gae_lambda, torch.arange(seqLength)).to(device)\n",
    "                                        \n",
    "                    ep_costs = (-1) * torch.log(self.d(ep_obs, ep_acts)).squeeze().detach()\n",
    "                    ep_disc_costs = ep_gms * ep_costs\n",
    "                    \n",
    "                    ep_disc_rets = torch.flip(torch.flip(\\\n",
    "                        ep_disc_costs.to(device), dims=[0]).cumsum(dim=0), dims=[0])\n",
    "                    # ep_disc_rets = FloatTensor([sum(ep_disc_costs[i:]) for i in range(seqLength)]).to(device)\n",
    "                    ep_rets = ep_disc_rets / ep_gms\n",
    "                    rets.append(ep_rets)\n",
    "\n",
    "                    self.v.eval()\n",
    "                    curr_vals = self.v(ep_obs).detach()\n",
    "                    next_vals = torch.cat(\n",
    "                        (self.v(ep_obs)[1:], FloatTensor([[0.]]).to(device))).detach()\n",
    "                    ep_deltas = ep_costs.unsqueeze(-1) + gae_gamma * next_vals - curr_vals\n",
    "                    ep_advs = FloatTensor([\n",
    "                        ((ep_gms * ep_lmbs)[:seqLength - j].unsqueeze(-1) * ep_deltas[j:]).sum()\n",
    "                        for j in range(seqLength)])\n",
    "\n",
    "                    advs.append(ep_advs)\n",
    "                    gms.append(ep_gms)\n",
    "\n",
    "            # print('nData:', nData)\n",
    "            print('[ampRatio, Acc.]:', end=' ')\n",
    "            lineBreakCount = 0\n",
    "            for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "                print('[{0}, {1:.3f}]'.\\\n",
    "                        format(noiseAmpRatio, correct[noiseAmpIndex]/nData), end=' ')\n",
    "                lineBreakCount += 1\n",
    "                if lineBreakCount == 4:\n",
    "                    print('')\n",
    "                    lineBreakCount = 0\n",
    "\n",
    "            # print('obs:', len(obs), 'acts:', len(acts))\n",
    "                \n",
    "                # rwd_iter_means.append(np.mean(rwd_iter))\n",
    "                # print(\n",
    "                #     \"Iterations: {},   Accuracy: {}\"\n",
    "                #     .format(i + 1, np.mean(rwd_iter))\n",
    "                # )\n",
    "\n",
    "                    # print('trAgentData', trAgentData.shape)\n",
    "                \n",
    "                \n",
    "            # exp_obs.append(trData['input'])\n",
    "                        \n",
    "        #     print(tsData['input'].shape, tsData['label'].shape)\n",
    "        #     exp_obs.append(tsData['input'])\n",
    "        #     exp_acts.append(tsData['label'])            \n",
    "            # ep_rwds = FloatTensor(ep_rwds)\n",
    "\n",
    "        # exp_rwd_mean = np.mean(exp_rwd_iter)\n",
    "        # print(\n",
    "        #     \"Expert Reward Mean: {}\".format(exp_rwd_mean)\n",
    "        # )\n",
    "\n",
    "        # print(exp_obs.shape, exp_acts.shape)\n",
    "        # exp_obs = FloatTensor(np.array(exp_obs))\n",
    "        # exp_acts = FloatTensor(np.array(exp_acts))\n",
    "        # return exp_rwd_mean, rwd_iter_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----White-box attack performance (Expert)----\n",
      "[ampRatio, Acc.]: [1e-05, 0.971] \n",
      "----Iteratons: 0----\n",
      "[ampRatio, Acc.]: [1e-05, 0.977] \n",
      "----Iteratons: 1----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GAIL(state_dim\u001b[38;5;241m=\u001b[39mnSubC\u001b[38;5;241m*\u001b[39mnRX, action_dim\u001b[38;5;241m=\u001b[39mnSubC\u001b[38;5;241m*\u001b[39mnRX,\\\n\u001b[1;32m      2\u001b[0m              discrete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice, train_config\u001b[38;5;241m=\u001b[39mGAILModelJson)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHARNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrExpLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrAgentLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtsLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 139\u001b[0m, in \u001b[0;36mGAIL.train\u001b[0;34m(self, HARNet, trExpLoader, trAgentLoader, tsLoader, render)\u001b[0m\n\u001b[1;32m    136\u001b[0m ep_gms \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(gae_gamma, torch\u001b[38;5;241m.\u001b[39marange(seqLength))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    137\u001b[0m ep_lmbs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(gae_lambda, torch\u001b[38;5;241m.\u001b[39marange(seqLength))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 139\u001b[0m ep_costs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m(\u001b[49m\u001b[43mep_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mep_acts\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    140\u001b[0m ep_disc_costs \u001b[38;5;241m=\u001b[39m ep_gms \u001b[38;5;241m*\u001b[39m ep_costs\n\u001b[1;32m    142\u001b[0m ep_disc_rets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflip(torch\u001b[38;5;241m.\u001b[39mflip(\\\n\u001b[1;32m    143\u001b[0m     ep_disc_costs\u001b[38;5;241m.\u001b[39mto(device), dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mcumsum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/wifiHAR_vel/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/24-RT_adv_HAR/GAIL/models/nets.py:97\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, states, actions)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, states, actions):\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/24-RT_adv_HAR/GAIL/models/nets.py:105\u001b[0m, in \u001b[0;36mDiscriminator.get_logits\u001b[0;34m(self, states, actions)\u001b[0m\n\u001b[1;32m    101\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_emb(actions\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m    103\u001b[0m sa \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([states, actions], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wifiHAR_vel/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/wifiHAR_vel/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/wifiHAR_vel/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/wifiHAR_vel/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GAIL(state_dim=nSubC*nRX, action_dim=nSubC*nRX,\\\n",
    "             discrete=False, device=device, train_config=GAILModelJson)\n",
    "model.train(HARNet, trExpLoader, trAgentLoader, tsLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wifiHAR_vel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
