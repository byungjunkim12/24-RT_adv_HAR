{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from GAIL.models.nets import Expert\n",
    "from GAIL.models.gail import GAIL\n",
    "\n",
    "from utilities import *\n",
    "from utilitiesDL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity: fall trExpDataset: 93 trAgentDataset: 39 tsDataset: 311\n",
      "activity: pickup trExpDataset: 103 trAgentDataset: 45 tsDataset: 347\n",
      "activity: run trExpDataset: 253 trAgentDataset: 109 tsDataset: 847\n",
      "activity: sitdown trExpDataset: 86 trAgentDataset: 37 tsDataset: 289\n",
      "activity: standup trExpDataset: 64 trAgentDataset: 27 tsDataset: 214\n",
      "activity: walk trExpDataset: 307 trAgentDataset: 132 tsDataset: 1026\n",
      "trExpLoader: 227 trAgentLoader 98 tsLoader: 304\n"
     ]
    }
   ],
   "source": [
    "DataFGMDir = '/project/iarpa/wifiHAR/HAR_survey/window_FGM/'\n",
    "LSTMModelDir = './savedModels/selected/'\n",
    "\n",
    "GAILModelJsonFileName = './GAIL/GAILModelConfig.json'\n",
    "GAILModelJson = json.load(open(GAILModelJsonFileName))\n",
    "\n",
    "GAILJsonFileName = './inputJson/GAIL/test.json'\n",
    "GAILJson = json.load(open(GAILJsonFileName))\n",
    "\n",
    "LSTMModelName = GAILJson['LSTMModelName']\n",
    "noiseAmpRatio = GAILJson['noiseAmpRatio']\n",
    "trDataRatio = GAILJson['trDataRatio']\n",
    "trExpDataRatio = GAILJson['trExpDataRatio']\n",
    "cudaID = GAILJson['cudaID']\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "if cudaID >= 0:\n",
    "    device = torch.device(\"cuda:\"+str(cudaID))\n",
    "    cudaAvbl = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    cudaAvbl = False\n",
    "\n",
    "dataType = LSTMModelName.split('_')[0]\n",
    "\n",
    "if dataType == 'survey':\n",
    "    fs = 1000 # 1 kHz\n",
    "    nSubC = 30\n",
    "    nRX = 3\n",
    "    \n",
    "    winLen = 1000\n",
    "    thres = 60\n",
    "    slideLen = 400\n",
    "    activities = ['fall', 'pickup', 'run', 'sitdown', 'standup', 'walk']\n",
    "\n",
    "LSTMType = LSTMModelName.split('_')[1]\n",
    "bidirectional = (LSTMType == 'BLSTM')\n",
    "nHidden = int(LSTMModelName.split('_')[3])\n",
    "threshold = int(LSTMModelName.split('_')[5])\n",
    "nLayer = int(LSTMModelName.split('_')[7])\n",
    "\n",
    "# Load the LSTM model\n",
    "HARNet = LSTMNet(nClasses=len(activities), input_size=nSubC*nRX, bidirectional=bidirectional,\\\n",
    "                hidden_size=nHidden, num_layers=1, seq_length=winLen//2, device=device)\n",
    "HARNet.load_state_dict(torch.load(LSTMModelDir + LSTMModelName + '.cpkt'))\n",
    "HARNet.to(device)\n",
    "\n",
    "# Load dataset labelled with FGM attack\n",
    "FGMdatasetDir = '/project/iarpa/wifiHAR/HAR_' + dataType + '/window_FGM/'\n",
    "dataDict = {file:[] for file in activities}\n",
    "tsDataDict = {file:[] for file in activities}\n",
    "\n",
    "trExpDataset = list()\n",
    "trAgentDataset = list()\n",
    "# trDataset = list()\n",
    "tsDataset = list()\n",
    "for actInd, activity in enumerate(activities):\n",
    "    dataDict[activity] = defaultdict(list)\n",
    "\n",
    "    dataActFileName = FGMdatasetDir + LSTMModelName + '_' + activity + '.pt'\n",
    "    dataAct = torch.load(dataActFileName)\n",
    "\n",
    "    dataDict[activity]['obs'] =\\\n",
    "        torch.reshape(torch.squeeze(dataAct[0, :, :]), (-1, winLen//2, nSubC*nRX)).detach().cpu().numpy()\n",
    "    dataDict[activity]['FGM'] = noiseAmpRatio *\\\n",
    "        torch.reshape(torch.squeeze(torch.squeeze(dataAct[1, :, :])),\\\n",
    "                      (-1, winLen//2, nSubC*nRX)).detach().cpu().numpy()\n",
    "    dataDict[activity]['label'] =\\\n",
    "        actInd * np.ones((dataDict[activity]['obs'].shape[0]), dtype=int)\n",
    "\n",
    "    datasetAct = FGMDataset(dataDict[activity], device)\n",
    "\n",
    "    trExpDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                                range(int(trDataRatio*trExpDataRatio*len(datasetAct)))))\n",
    "    trAgentDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                                  range(int(trDataRatio*trExpDataRatio*len(datasetAct)),\\\n",
    "                                                        int(trDataRatio*len(datasetAct)))))\n",
    "    # trDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "    #                                         range(int(trDataRatio*len(datasetAct)))))\n",
    "    tsDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                             range(int(trDataRatio*len(datasetAct)), len(datasetAct))))\n",
    "\n",
    "    # print('activity:', activity, 'trDataset:', len(trDataset[-1]), 'tsDataset:', len(tsDataset[-1]))\n",
    "    print('activity:', activity, 'trExpDataset:', len(trExpDataset[-1]),\\\n",
    "          'trAgentDataset:', len(trAgentDataset[-1]), 'tsDataset:', len(tsDataset[-1]))\n",
    "\n",
    "\n",
    "trExpLoader = DataLoader(torch.utils.data.ConcatDataset(trExpDataset),\\\n",
    "                      batch_size=4, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "trAgentLoader = DataLoader(torch.utils.data.ConcatDataset(trAgentDataset),\\\n",
    "                      batch_size=4, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "# trLoader = DataLoader(torch.utils.data.ConcatDataset(trDataset),\\\n",
    "#                       batch_size=4, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "tsLoader = DataLoader(torch.utils.data.ConcatDataset(tsDataset),\\\n",
    "                      batch_size=10, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "\n",
    "# print('trExpLoader:', len(trLoader), 'tsLoader:', len(tsLoader))\n",
    "print('trExpLoader:', len(trExpLoader), 'trAgentLoader', len(trAgentLoader), 'tsLoader:', len(tsLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.nn import Module\n",
    "\n",
    "from GAIL.models.nets import PolicyNetwork, ValueNetwork, Discriminator\n",
    "from GAIL.utils.funcs import get_flat_grads, get_flat_params, set_params, \\\n",
    "    conjugate_gradient, rescale_and_linesearch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    from torch import FloatTensor\n",
    "\n",
    "\n",
    "class GAIL(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        discrete,\n",
    "        device,\n",
    "        train_config=None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.discrete = discrete\n",
    "        self.device = device\n",
    "        self.train_config = train_config\n",
    "\n",
    "        self.pi = PolicyNetwork(self.state_dim, self.action_dim, self.discrete, self.device)\n",
    "        self.v = ValueNetwork(self.state_dim, self.device)\n",
    "        self.d = Discriminator(self.state_dim, self.action_dim, self.discrete, self.device)\n",
    "\n",
    "    def get_networks(self):\n",
    "        return [self.pi, self.v]\n",
    "\n",
    "    def act(self, state):\n",
    "        self.pi.eval()\n",
    "        state = FloatTensor(state)\n",
    "        action = self.pi(state).sample()\n",
    "        # action = distb.sample().detach().cpu().numpy()\n",
    "\n",
    "        return action\n",
    "\n",
    "    def train(self, HARNet, trExpLoader, trAgentLoader, tsLoader, render=False):\n",
    "        num_iters = self.train_config[\"num_iters\"]\n",
    "        num_steps_per_iter = self.train_config[\"num_steps_per_iter\"]\n",
    "        horizon = self.train_config[\"horizon\"]\n",
    "        lambda_ = self.train_config[\"lambda\"]\n",
    "        gae_gamma = self.train_config[\"gae_gamma\"]\n",
    "        gae_lambda = self.train_config[\"gae_lambda\"]\n",
    "        eps = self.train_config[\"epsilon\"]\n",
    "        max_kl = self.train_config[\"max_kl\"]\n",
    "        cg_damping = self.train_config[\"cg_damping\"]\n",
    "        normalize_advantage = self.train_config[\"normalize_advantage\"]\n",
    "\n",
    "        opt_d = torch.optim.Adam(self.d.parameters())\n",
    "\n",
    "        # noiseAmpRatioList = [1e-4, 1e-3, 1e-2, 0.1]\n",
    "        noiseAmpRatioList = [1e-3, 1e-2]\n",
    "        print('----White-box attack performance (Expert)----')\n",
    "        lineBreakCount = 0\n",
    "        print('[ampRatio, Acc.]:', end=' ')\n",
    "        for noiseAmpRatio in noiseAmpRatioList:\n",
    "            nDataTs = 0.\n",
    "            correct = 0.\n",
    "            for tsBatch in tsLoader:\n",
    "                pred_l,label_l = getPredsGAIL(tsBatch['obs'], tsBatch['FGM'], tsBatch['label'],\\\n",
    "                                              HARNet, noiseAmpRatio)\n",
    "                nDataTs += len(label_l)\n",
    "                for pred, label in zip(pred_l, label_l):\n",
    "                    correct += (pred == label)\n",
    "                # accuracyList.append(correct/nData)\n",
    "            print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nDataTs), end=' ')\n",
    "            lineBreakCount += 1\n",
    "            if lineBreakCount == 4:\n",
    "                print('')\n",
    "                lineBreakCount = 0\n",
    "\n",
    "        nDataTrExp = 0\n",
    "        for trExpBatch in trExpLoader:\n",
    "            nDataTrExp += trExpBatch['obs'].shape[0]\n",
    "        nDataTrAgent = 0\n",
    "        for trAgentBatch in trAgentLoader:\n",
    "            nDataTrAgent += trAgentBatch['obs'].shape[0]\n",
    "\n",
    "        if lineBreakCount != 0:\n",
    "            print('')\n",
    "\n",
    "        print('nDataTrExp:', nDataTrExp, 'nDataTrAgent:', nDataTrAgent, 'nDataTs:', int(nDataTs))\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            if lineBreakCount != 0 and i!= 0:\n",
    "                print('')\n",
    "            print('----Iteratons: {}----'.format(i))\n",
    "            \n",
    "            obs = []\n",
    "            acts = []\n",
    "            rets = []\n",
    "            advs = []\n",
    "            gms = []\n",
    "\n",
    "            nData = 0\n",
    "            correct = [0. for _ in noiseAmpRatioList]\n",
    "            for trAgentBatch in trAgentLoader:\n",
    "\n",
    "                nData += trAgentBatch['obs'].shape[0]\n",
    "                seqLength = trAgentBatch['obs'].shape[1]\n",
    "                obsAmp = LA.norm(trAgentBatch['obs'].view(trAgentBatch['obs'].shape[0], -1), dim=1)\n",
    "                # print('obs amp:', obsAmp)\n",
    "                obsBatchFlatten = trAgentBatch['obs'].transpose(0, 1).reshape(-1, trAgentBatch['obs'].shape[2])\n",
    "                actBatchFlatten = self.act(obsBatchFlatten)\n",
    "                actBatch = torch.reshape(actBatchFlatten, ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)\n",
    "                # actTorch = torch.reshape(torch.from_numpy(act), ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)\n",
    "                \n",
    "                lineBreakCount = 0\n",
    "                for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "                    pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], actBatch, trAgentBatch['label'],\\\n",
    "                                                    HARNet, noiseAmpRatio)\n",
    "\n",
    "                    # print(pred_l, label_l)\n",
    "                    for pred, label in zip(pred_l, label_l):\n",
    "                        correct[noiseAmpIndex] += (pred == label)\n",
    "                        # print(correct)\n",
    "                    \n",
    "                obs.append(obsBatchFlatten)\n",
    "                acts.append(actBatchFlatten)\n",
    "\n",
    "                for i, trAgentData in enumerate(trAgentBatch['obs']):\n",
    "                    ep_obs = trAgentData\n",
    "                    ep_acts = torch.squeeze(actBatch[i, :, :])\n",
    "                    ep_gms = torch.pow(gae_gamma, torch.arange(seqLength)).to(device)\n",
    "                    ep_lmbs = torch.pow(gae_lambda, torch.arange(seqLength)).to(device)\n",
    "                                        \n",
    "                    ep_costs = (-1) * torch.log(self.d(ep_obs, ep_acts)).squeeze().detach()\n",
    "                    ep_disc_costs = ep_gms * ep_costs\n",
    "                    ep_disc_rets = torch.flip(torch.flip(\\\n",
    "                        ep_disc_costs.to(device), dims=[0]).cumsum(dim=0), dims=[0])\n",
    "                    # ep_disc_rets = FloatTensor([sum(ep_disc_costs[i:]) for i in range(seqLength)]).to(device)\n",
    "                    ep_rets = ep_disc_rets / ep_gms\n",
    "                    rets.append(ep_rets)\n",
    "\n",
    "                    self.v.eval()\n",
    "                    curr_vals = self.v(ep_obs).detach()\n",
    "                    next_vals = torch.cat(\n",
    "                        (self.v(ep_obs)[1:], FloatTensor([[0.]]).to(device))).detach()\n",
    "                    ep_deltas = ep_costs.unsqueeze(-1) + gae_gamma * next_vals - curr_vals\n",
    "                    ep_advs = FloatTensor([\n",
    "                        ((ep_gms * ep_lmbs)[:seqLength - j].unsqueeze(-1) * ep_deltas[j:]).sum()\n",
    "                        for j in range(seqLength)])\n",
    "\n",
    "                    advs.append(ep_advs)\n",
    "                    gms.append(ep_gms)\n",
    "            \n",
    "            advs = torch.cat(advs).to(device)\n",
    "            if normalize_advantage:\n",
    "                advs = (advs - advs.mean()) / (advs.std() + 1e-8)\n",
    "\n",
    "            self.d.train()\n",
    "            expScores = torch.Tensor().to(device)\n",
    "            agentScores = torch.Tensor().to(device)\n",
    "            for trExpBatch in trExpLoader:\n",
    "                expObsBatch = trExpBatch['obs'].transpose(0, 1).reshape(-1, trExpBatch['obs'].shape[2])\n",
    "                expActBatch = trExpBatch['FGM'].transpose(0, 1).reshape(-1, trExpBatch['FGM'].shape[2])\n",
    "                # expScores = self.d.get_logits(expObsBatch, expActBatch)\n",
    "                expScores = torch.cat((expScores, self.d.get_logits(expObsBatch, expActBatch)), dim=0)\n",
    "                \n",
    "            for agentObsBatch, agentActsBatch in zip(obs, acts):\n",
    "                agentScores = torch.cat((agentScores, self.d.get_logits(agentObsBatch, agentActsBatch)), dim=0)\n",
    "            \n",
    "            opt_d.zero_grad()\n",
    "            lossExp = torch.nn.functional.binary_cross_entropy_with_logits(\\\n",
    "                expScores, torch.zeros_like(expScores))\n",
    "            del expScores\n",
    "            lossAgent = torch.nn.functional.binary_cross_entropy_with_logits(\\\n",
    "                agentScores, torch.ones_like(agentScores))\n",
    "            del agentScores\n",
    "            loss = lossExp + lossAgent\n",
    "            loss.backward()\n",
    "            opt_d.step()\n",
    "\n",
    "            # for expScores in expScoresList:\n",
    "            #     lossExp += torch.nn.functional.binary_cross_entropy_with_logits(\\\n",
    "            #         expScores, torch.zeros_like(expScores))\n",
    "\n",
    "            # nov_scores = self.d.get_logits(obs, acts)\n",
    "            # print accuracies\n",
    "            print('[ampRatio, Acc.]:', end=' ')\n",
    "            lineBreakCount = 0\n",
    "            for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "                print('[{0}, {1:.3f}]'.\\\n",
    "                        format(noiseAmpRatio, correct[noiseAmpIndex]/nData), end=' ')\n",
    "                lineBreakCount += 1\n",
    "                if lineBreakCount == 4:\n",
    "                    print('')\n",
    "                    lineBreakCount = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----White-box attack performance (Expert)----\n",
      "[ampRatio, Acc.]: [0.001, 0.953] [0.01, 0.585] \n",
      "nDataTrExp: 906 nDataTrAgent: 389 nDataTs: 3034\n",
      "----Iteratons: 0----\n",
      "torch.Size([453000, 1]) torch.Size([194500, 1])\n",
      "[ampRatio, Acc.]: [0.001, 0.977] [0.01, 0.977] \n",
      "----Iteratons: 1----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GAIL(state_dim\u001b[38;5;241m=\u001b[39mnSubC\u001b[38;5;241m*\u001b[39mnRX, action_dim\u001b[38;5;241m=\u001b[39mnSubC\u001b[38;5;241m*\u001b[39mnRX,\\\n\u001b[1;32m      2\u001b[0m              discrete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice, train_config\u001b[38;5;241m=\u001b[39mGAILModelJson)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHARNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrExpLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrAgentLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtsLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 152\u001b[0m, in \u001b[0;36mGAIL.train\u001b[0;34m(self, HARNet, trExpLoader, trAgentLoader, tsLoader, render)\u001b[0m\n\u001b[1;32m    149\u001b[0m next_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    150\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv(ep_obs)[\u001b[38;5;241m1\u001b[39m:], FloatTensor([[\u001b[38;5;241m0.\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device)))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    151\u001b[0m ep_deltas \u001b[38;5;241m=\u001b[39m ep_costs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m gae_gamma \u001b[38;5;241m*\u001b[39m next_vals \u001b[38;5;241m-\u001b[39m curr_vals\n\u001b[0;32m--> 152\u001b[0m ep_advs \u001b[38;5;241m=\u001b[39m FloatTensor([\n\u001b[1;32m    153\u001b[0m     ((ep_gms \u001b[38;5;241m*\u001b[39m ep_lmbs)[:seqLength \u001b[38;5;241m-\u001b[39m j]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m ep_deltas[j:])\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seqLength)])\n\u001b[1;32m    156\u001b[0m advs\u001b[38;5;241m.\u001b[39mappend(ep_advs)\n\u001b[1;32m    157\u001b[0m gms\u001b[38;5;241m.\u001b[39mappend(ep_gms)\n",
      "Cell \u001b[0;32mIn[20], line 153\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    149\u001b[0m next_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    150\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv(ep_obs)[\u001b[38;5;241m1\u001b[39m:], FloatTensor([[\u001b[38;5;241m0.\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device)))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    151\u001b[0m ep_deltas \u001b[38;5;241m=\u001b[39m ep_costs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m gae_gamma \u001b[38;5;241m*\u001b[39m next_vals \u001b[38;5;241m-\u001b[39m curr_vals\n\u001b[1;32m    152\u001b[0m ep_advs \u001b[38;5;241m=\u001b[39m FloatTensor([\n\u001b[0;32m--> 153\u001b[0m     (\u001b[43m(\u001b[49m\u001b[43mep_gms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mep_lmbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mseqLength\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m ep_deltas[j:])\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seqLength)])\n\u001b[1;32m    156\u001b[0m advs\u001b[38;5;241m.\u001b[39mappend(ep_advs)\n\u001b[1;32m    157\u001b[0m gms\u001b[38;5;241m.\u001b[39mappend(ep_gms)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GAIL(state_dim=nSubC*nRX, action_dim=nSubC*nRX,\\\n",
    "             discrete=False, device=device, train_config=GAILModelJson)\n",
    "model.train(HARNet, trExpLoader, trAgentLoader, tsLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wifiHAR_vel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
