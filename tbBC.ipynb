{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Module\n",
    "from collections import defaultdict\n",
    "\n",
    "from GAIL.models.nets import Expert\n",
    "from GAIL.models.gail import GAIL\n",
    "\n",
    "from utilities import *\n",
    "from utilitiesDL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype: TAR\n",
      "dataPath: /project/iarpa/wifiHAR/HAR_TAR/noWin_dSamp_10_pad_9/\n"
     ]
    }
   ],
   "source": [
    "jsonFileName = './inputJson/genData_TAR.json'\n",
    "attackScheme = \"BC\"\n",
    "\n",
    "f = open(jsonFileName)\n",
    "inputJson = json.load(f)\n",
    "dataPathBase = inputJson['dataPathBase']\n",
    "dataType = inputJson['dataType']\n",
    "padLen = inputJson['padLen']\n",
    "dataWin = inputJson['dataWin']\n",
    "cudaID = 5\n",
    "f.close()\n",
    "\n",
    "print(\"Datatype:\", dataType)\n",
    "if dataType == 'JAR':\n",
    "    fs = 320\n",
    "    nSubC = 30\n",
    "    nRX = 3\n",
    "    \n",
    "    dSampFactor = 1\n",
    "    activities = ['sitstill', 'falldown', 'liedown', 'standstill', 'walk', 'turn', 'stand', 'sit']\n",
    "\n",
    "elif dataType == 'TAR':\n",
    "    fs = 1000 # 1 kHz\n",
    "    nSubC = 30\n",
    "    nRX = 3\n",
    "    \n",
    "    dSampFactor = 10\n",
    "    padLen = 9\n",
    "    activities = ['bed', 'fall', 'run', 'sitdown', 'standup', 'walk']\n",
    "    # activities = ['fall', 'pickup', 'run', 'sitdown', 'standup', 'walk']\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "if cudaID >= 0:\n",
    "    device = torch.device(\"cuda:\"+str(cudaID))\n",
    "    cudaAvbl = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    cudaAvbl = False\n",
    "\n",
    "dataPath = dataPathBase + \"HAR_\" + dataType + \"/\"\n",
    "if dataType == 'JAR':\n",
    "    dataPath = dataPath + \"dSamp_\" + str(dSampFactor) + \"/\"\n",
    "elif dataType == 'TAR':\n",
    "    if dataWin:\n",
    "        padLen = 250\n",
    "        dataPath = dataPath + \"win_dSamp_\" + str(dSampFactor) + \"_pad_\" + str(padLen) + \"/\"\n",
    "        # dataPath = dataPath + \"win_dSamp_\" + str(dSampFactor) + \"_\" + str(attackScheme) + \"/\"\n",
    "    else:\n",
    "        dataPath = dataPath + \"noWin_dSamp_\" + str(dSampFactor) + \"_pad_\" + str(padLen) + \"/\"\n",
    "print('dataPath:', dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 25\n",
      "TAR_BiLSTM_H_200_dS_10 TAR_target_BiLSTM_H_200_win\n",
      "torch.Size([1296, 90]) torch.Size([255, 90]) torch.Size([1956, 90]) torch.Size([387, 90]) torch.Size([1926, 90]) torch.Size([381, 90]) torch.Size([1436, 90]) torch.Size([283, 90]) torch.Size([2176, 90]) torch.Size([431, 90]) torch.Size([1516, 90]) torch.Size([299, 90]) torch.Size([1536, 90]) torch.Size([303, 90]) torch.Size([1621, 90]) torch.Size([320, 90]) torch.Size([1381, 90]) torch.Size([272, 90]) torch.Size([1516, 90]) torch.Size([299, 90]) torch.Size([2111, 90]) torch.Size([418, 90]) torch.Size([1771, 90]) torch.Size([350, 90]) torch.Size([1686, 90]) torch.Size([333, 90]) torch.Size([1296, 90]) torch.Size([255, 90]) torch.Size([2041, 90]) torch.Size([404, 90]) torch.Size([2196, 90]) torch.Size([435, 90]) torch.Size([1956, 90]) torch.Size([387, 90]) torch.Size([2431, 90]) torch.Size([482, 90]) torch.Size([1651, 90]) torch.Size([326, 90]) torch.Size([1431, 90]) torch.Size([282, 90]) torch.Size([1381, 90]) torch.Size([272, 90]) torch.Size([1411, 90]) torch.Size([278, 90]) torch.Size([1736, 90]) torch.Size([343, 90]) torch.Size([1566, 90]) torch.Size([309, 90]) torch.Size([1751, 90]) torch.Size([346, 90]) torch.Size([1531, 90]) torch.Size([302, 90]) torch.Size([2346, 90]) torch.Size([465, 90]) torch.Size([1871, 90]) torch.Size([370, 90]) torch.Size([1841, 90]) torch.Size([364, 90]) torch.Size([1856, 90]) torch.Size([367, 90]) torch.Size([1856, 90]) torch.Size([367, 90]) torch.Size([1786, 90]) torch.Size([353, 90]) torch.Size([1976, 90]) torch.Size([391, 90]) torch.Size([1956, 90]) torch.Size([387, 90]) torch.Size([1786, 90]) torch.Size([353, 90]) torch.Size([2211, 90]) torch.Size([438, 90]) torch.Size([1621, 90]) torch.Size([320, 90]) torch.Size([1756, 90]) torch.Size([347, 90]) torch.Size([1651, 90]) torch.Size([326, 90]) torch.Size([1906, 90]) torch.Size([377, 90]) torch.Size([1996, 90]) torch.Size([395, 90]) torch.Size([1451, 90]) torch.Size([286, 90]) torch.Size([2011, 90]) torch.Size([398, 90]) torch.Size([2091, 90]) torch.Size([414, 90]) torch.Size([1806, 90]) torch.Size([357, 90]) torch.Size([1921, 90]) torch.Size([380, 90]) torch.Size([1431, 90]) torch.Size([282, 90]) torch.Size([2161, 90]) torch.Size([428, 90]) torch.Size([1671, 90]) torch.Size([330, 90]) torch.Size([1501, 90]) torch.Size([296, 90]) torch.Size([981, 90]) torch.Size([192, 90]) torch.Size([1771, 90]) torch.Size([350, 90]) torch.Size([2176, 90]) torch.Size([431, 90]) torch.Size([1551, 90]) torch.Size([306, 90]) torch.Size([2261, 90]) torch.Size([448, 90]) torch.Size([2091, 90]) torch.Size([414, 90]) torch.Size([1791, 90]) torch.Size([354, 90]) torch.Size([2161, 90]) torch.Size([428, 90]) torch.Size([1906, 90]) torch.Size([377, 90]) torch.Size([2011, 90]) torch.Size([398, 90]) torch.Size([1756, 90]) torch.Size([347, 90]) torch.Size([2196, 90]) torch.Size([435, 90]) torch.Size([1651, 90]) torch.Size([326, 90]) torch.Size([2126, 90]) torch.Size([421, 90]) torch.Size([1636, 90]) torch.Size([323, 90]) torch.Size([1941, 90]) torch.Size([384, 90]) torch.Size([1501, 90]) torch.Size([296, 90]) torch.Size([1751, 90]) torch.Size([346, 90]) torch.Size([1536, 90]) torch.Size([303, 90]) torch.Size([1571, 90]) torch.Size([310, 90]) torch.Size([1551, 90]) torch.Size([306, 90]) torch.Size([1791, 90]) torch.Size([354, 90]) torch.Size([2011, 90]) torch.Size([398, 90]) torch.Size([1686, 90]) torch.Size([333, 90]) torch.Size([1481, 90]) torch.Size([292, 90]) torch.Size([2146, 90]) torch.Size([425, 90]) torch.Size([1466, 90]) torch.Size([289, 90]) torch.Size([2206, 90]) torch.Size([437, 90]) torch.Size([1941, 90]) torch.Size([384, 90]) activity: bed nData: 79\n",
      "torch.Size([971, 90]) torch.Size([190, 90]) torch.Size([1621, 90]) torch.Size([320, 90]) torch.Size([1091, 90]) torch.Size([214, 90]) torch.Size([1246, 90]) torch.Size([245, 90]) torch.Size([1246, 90]) torch.Size([245, 90]) torch.Size([1516, 90]) torch.Size([299, 90]) torch.Size([1366, 90]) torch.Size([269, 90]) torch.Size([1616, 90]) torch.Size([319, 90]) torch.Size([906, 90]) torch.Size([177, 90]) torch.Size([1566, 90]) torch.Size([309, 90]) torch.Size([1281, 90]) torch.Size([252, 90]) torch.Size([1301, 90]) torch.Size([256, 90]) torch.Size([1386, 90]) torch.Size([273, 90]) torch.Size([1281, 90]) torch.Size([252, 90]) torch.Size([1636, 90]) torch.Size([323, 90]) torch.Size([1451, 90]) torch.Size([286, 90]) torch.Size([1261, 90]) torch.Size([248, 90]) torch.Size([1486, 90]) torch.Size([293, 90]) torch.Size([1176, 90]) torch.Size([231, 90]) torch.Size([1281, 90]) torch.Size([252, 90]) torch.Size([1621, 90]) torch.Size([320, 90]) torch.Size([1261, 90]) torch.Size([248, 90]) torch.Size([1416, 90]) torch.Size([279, 90]) torch.Size([1226, 90]) torch.Size([241, 90]) torch.Size([1316, 90]) torch.Size([259, 90]) torch.Size([1301, 90]) torch.Size([256, 90]) torch.Size([1231, 90]) torch.Size([242, 90]) torch.Size([891, 90]) torch.Size([174, 90]) torch.Size([956, 90]) torch.Size([187, 90]) torch.Size([1046, 90]) torch.Size([205, 90]) torch.Size([1481, 90]) torch.Size([292, 90]) torch.Size([1266, 90]) torch.Size([249, 90]) torch.Size([1211, 90]) torch.Size([238, 90]) torch.Size([1076, 90]) torch.Size([211, 90]) torch.Size([1301, 90]) torch.Size([256, 90]) torch.Size([1261, 90]) torch.Size([248, 90]) torch.Size([841, 90]) torch.Size([164, 90]) torch.Size([1091, 90]) torch.Size([214, 90]) torch.Size([806, 90]) torch.Size([157, 90]) torch.Size([1261, 90]) torch.Size([248, 90]) torch.Size([1246, 90]) torch.Size([245, 90]) torch.Size([1296, 90]) torch.Size([255, 90]) torch.Size([1126, 90]) torch.Size([221, 90]) torch.Size([1401, 90]) torch.Size([276, 90]) torch.Size([1501, 90]) torch.Size([296, 90]) torch.Size([1026, 90]) torch.Size([201, 90]) torch.Size([1566, 90]) torch.Size([309, 90]) torch.Size([1111, 90]) torch.Size([218, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([911, 90]) torch.Size([178, 90]) torch.Size([1346, 90]) torch.Size([265, 90]) torch.Size([1196, 90]) torch.Size([235, 90]) torch.Size([1366, 90]) torch.Size([269, 90]) torch.Size([1301, 90]) torch.Size([256, 90]) torch.Size([1361, 90]) torch.Size([268, 90]) torch.Size([1196, 90]) torch.Size([235, 90]) torch.Size([1346, 90]) torch.Size([265, 90]) torch.Size([1451, 90]) torch.Size([286, 90]) torch.Size([991, 90]) torch.Size([194, 90]) torch.Size([1601, 90]) torch.Size([316, 90]) torch.Size([1131, 90]) torch.Size([222, 90]) torch.Size([1006, 90]) torch.Size([197, 90]) torch.Size([1111, 90]) torch.Size([218, 90]) torch.Size([1671, 90]) torch.Size([330, 90]) torch.Size([1366, 90]) torch.Size([269, 90]) torch.Size([1296, 90]) torch.Size([255, 90]) torch.Size([1331, 90]) torch.Size([262, 90]) torch.Size([1141, 90]) torch.Size([224, 90]) torch.Size([1076, 90]) torch.Size([211, 90]) torch.Size([1076, 90]) torch.Size([211, 90]) torch.Size([1111, 90]) torch.Size([218, 90]) torch.Size([1331, 90]) torch.Size([262, 90]) torch.Size([1346, 90]) torch.Size([265, 90]) torch.Size([1026, 90]) torch.Size([201, 90]) torch.Size([1216, 90]) torch.Size([239, 90]) torch.Size([1111, 90]) torch.Size([218, 90]) torch.Size([1006, 90]) torch.Size([197, 90]) torch.Size([1401, 90]) torch.Size([276, 90]) torch.Size([1176, 90]) torch.Size([231, 90]) activity: fall nData: 79\n",
      "torch.Size([3451, 90]) torch.Size([686, 90]) torch.Size([2516, 90]) torch.Size([499, 90]) torch.Size([1671, 90]) torch.Size([330, 90]) torch.Size([2551, 90]) torch.Size([506, 90]) torch.Size([1871, 90]) torch.Size([370, 90]) torch.Size([3331, 90]) torch.Size([662, 90]) torch.Size([4991, 90]) torch.Size([994, 90]) torch.Size([4491, 90]) torch.Size([894, 90]) torch.Size([2736, 90]) torch.Size([543, 90]) torch.Size([3566, 90]) torch.Size([709, 90]) torch.Size([1961, 90]) torch.Size([388, 90]) torch.Size([2841, 90]) torch.Size([564, 90]) torch.Size([1751, 90]) torch.Size([346, 90]) torch.Size([4161, 90]) torch.Size([828, 90]) torch.Size([2571, 90]) torch.Size([510, 90]) torch.Size([3211, 90]) torch.Size([638, 90]) torch.Size([1956, 90]) torch.Size([387, 90]) torch.Size([5676, 90]) torch.Size([1131, 90]) torch.Size([1776, 90]) torch.Size([351, 90]) torch.Size([3381, 90]) torch.Size([672, 90]) torch.Size([2736, 90]) torch.Size([543, 90]) torch.Size([3266, 90]) torch.Size([649, 90]) torch.Size([2876, 90]) torch.Size([571, 90]) torch.Size([2566, 90]) torch.Size([509, 90]) torch.Size([3046, 90]) torch.Size([605, 90]) torch.Size([1871, 90]) torch.Size([370, 90]) torch.Size([1806, 90]) torch.Size([357, 90]) torch.Size([4386, 90]) torch.Size([873, 90]) torch.Size([1771, 90]) torch.Size([350, 90]) torch.Size([2996, 90]) torch.Size([595, 90]) torch.Size([2536, 90]) torch.Size([503, 90]) torch.Size([3431, 90]) torch.Size([682, 90]) torch.Size([1801, 90]) torch.Size([356, 90]) torch.Size([4706, 90]) torch.Size([937, 90]) torch.Size([3486, 90]) torch.Size([693, 90]) torch.Size([1871, 90]) torch.Size([370, 90]) torch.Size([3146, 90]) torch.Size([625, 90]) torch.Size([3246, 90]) torch.Size([645, 90]) torch.Size([1911, 90]) torch.Size([378, 90]) torch.Size([1786, 90]) torch.Size([353, 90]) torch.Size([2046, 90]) torch.Size([405, 90]) torch.Size([3296, 90]) torch.Size([655, 90]) torch.Size([1911, 90]) torch.Size([378, 90]) torch.Size([2756, 90]) torch.Size([547, 90]) torch.Size([4891, 90]) torch.Size([974, 90]) torch.Size([4741, 90]) torch.Size([944, 90]) torch.Size([3281, 90]) torch.Size([652, 90]) torch.Size([4041, 90]) torch.Size([804, 90]) torch.Size([2821, 90]) torch.Size([560, 90]) torch.Size([2046, 90]) torch.Size([405, 90]) torch.Size([3551, 90]) torch.Size([706, 90]) torch.Size([2941, 90]) torch.Size([584, 90]) torch.Size([4736, 90]) torch.Size([943, 90]) torch.Size([4566, 90]) torch.Size([909, 90]) torch.Size([3006, 90]) torch.Size([597, 90]) torch.Size([4416, 90]) torch.Size([879, 90]) torch.Size([1811, 90]) torch.Size([358, 90]) torch.Size([2771, 90]) torch.Size([550, 90]) torch.Size([4196, 90]) torch.Size([835, 90]) torch.Size([4636, 90]) torch.Size([923, 90]) torch.Size([3891, 90]) torch.Size([774, 90]) torch.Size([3516, 90]) torch.Size([699, 90]) torch.Size([3351, 90]) torch.Size([666, 90]) torch.Size([4416, 90]) torch.Size([879, 90]) torch.Size([4671, 90]) torch.Size([930, 90]) torch.Size([2601, 90]) torch.Size([516, 90]) torch.Size([3096, 90]) torch.Size([615, 90]) torch.Size([2076, 90]) torch.Size([411, 90]) torch.Size([3446, 90]) torch.Size([685, 90]) torch.Size([4591, 90]) torch.Size([914, 90]) torch.Size([4431, 90]) torch.Size([882, 90]) torch.Size([3126, 90]) torch.Size([621, 90]) torch.Size([3276, 90]) torch.Size([651, 90]) torch.Size([2146, 90]) torch.Size([425, 90]) torch.Size([3331, 90]) torch.Size([662, 90]) torch.Size([3351, 90]) torch.Size([666, 90]) torch.Size([3331, 90]) torch.Size([662, 90]) torch.Size([1736, 90]) torch.Size([343, 90]) torch.Size([2771, 90]) torch.Size([550, 90]) torch.Size([3856, 90]) torch.Size([767, 90]) activity: run nData: 80\n",
      "torch.Size([1261, 90]) torch.Size([248, 90]) torch.Size([871, 90]) torch.Size([170, 90]) torch.Size([961, 90]) torch.Size([188, 90]) torch.Size([646, 90]) torch.Size([125, 90]) torch.Size([1076, 90]) torch.Size([211, 90]) torch.Size([1346, 90]) torch.Size([265, 90]) torch.Size([1741, 90]) torch.Size([344, 90]) torch.Size([1196, 90]) torch.Size([235, 90]) torch.Size([1026, 90]) torch.Size([201, 90]) torch.Size([1651, 90]) torch.Size([326, 90]) torch.Size([926, 90]) torch.Size([181, 90]) torch.Size([1266, 90]) torch.Size([249, 90]) torch.Size([1361, 90]) torch.Size([268, 90]) torch.Size([1601, 90]) torch.Size([316, 90]) torch.Size([941, 90]) torch.Size([184, 90]) torch.Size([1231, 90]) torch.Size([242, 90]) torch.Size([1261, 90]) torch.Size([248, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([1401, 90]) torch.Size([276, 90]) torch.Size([1211, 90]) torch.Size([238, 90]) torch.Size([1281, 90]) torch.Size([252, 90]) torch.Size([1246, 90]) torch.Size([245, 90]) torch.Size([821, 90]) torch.Size([160, 90]) torch.Size([1011, 90]) torch.Size([198, 90]) torch.Size([991, 90]) torch.Size([194, 90]) torch.Size([1346, 90]) torch.Size([265, 90]) torch.Size([856, 90]) torch.Size([167, 90]) torch.Size([856, 90]) torch.Size([167, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([1381, 90]) torch.Size([272, 90]) torch.Size([1076, 90]) torch.Size([211, 90]) torch.Size([906, 90]) torch.Size([177, 90]) torch.Size([956, 90]) torch.Size([187, 90]) torch.Size([856, 90]) torch.Size([167, 90]) torch.Size([1331, 90]) torch.Size([262, 90]) torch.Size([991, 90]) torch.Size([194, 90]) torch.Size([1231, 90]) torch.Size([242, 90]) torch.Size([1196, 90]) torch.Size([235, 90]) torch.Size([1146, 90]) torch.Size([225, 90]) torch.Size([941, 90]) torch.Size([184, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([1316, 90]) torch.Size([259, 90]) torch.Size([941, 90]) torch.Size([184, 90]) torch.Size([1291, 90]) torch.Size([254, 90]) torch.Size([1161, 90]) torch.Size([228, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([1091, 90]) torch.Size([214, 90]) torch.Size([771, 90]) torch.Size([150, 90]) torch.Size([991, 90]) torch.Size([194, 90]) torch.Size([1736, 90]) torch.Size([343, 90]) torch.Size([891, 90]) torch.Size([174, 90]) torch.Size([1431, 90]) torch.Size([282, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([991, 90]) torch.Size([194, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([1566, 90]) torch.Size([309, 90]) torch.Size([1181, 90]) torch.Size([232, 90]) torch.Size([891, 90]) torch.Size([174, 90]) torch.Size([1331, 90]) torch.Size([262, 90]) torch.Size([1006, 90]) torch.Size([197, 90]) torch.Size([976, 90]) torch.Size([191, 90]) torch.Size([926, 90]) torch.Size([181, 90]) torch.Size([1126, 90]) torch.Size([221, 90]) torch.Size([1011, 90]) torch.Size([198, 90]) torch.Size([1471, 90]) torch.Size([290, 90]) torch.Size([1216, 90]) torch.Size([239, 90]) torch.Size([1566, 90]) torch.Size([309, 90]) torch.Size([1586, 90]) torch.Size([313, 90]) torch.Size([1246, 90]) torch.Size([245, 90]) torch.Size([1281, 90]) torch.Size([252, 90]) torch.Size([1076, 90]) torch.Size([211, 90]) torch.Size([1161, 90]) torch.Size([228, 90]) torch.Size([786, 90]) torch.Size([153, 90]) torch.Size([1011, 90]) torch.Size([198, 90]) torch.Size([806, 90]) torch.Size([157, 90]) torch.Size([1446, 90]) torch.Size([285, 90]) torch.Size([806, 90]) torch.Size([157, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([1281, 90]) torch.Size([252, 90]) torch.Size([1296, 90]) torch.Size([255, 90]) activity: sitdown nData: 80\n",
      "torch.Size([721, 90]) torch.Size([140, 90]) torch.Size([926, 90]) torch.Size([181, 90]) torch.Size([991, 90]) torch.Size([194, 90]) torch.Size([821, 90]) torch.Size([160, 90]) torch.Size([786, 90]) torch.Size([153, 90]) torch.Size([841, 90]) torch.Size([164, 90]) torch.Size([856, 90]) torch.Size([167, 90]) torch.Size([841, 90]) torch.Size([164, 90]) torch.Size([771, 90]) torch.Size([150, 90]) torch.Size([826, 90]) torch.Size([161, 90]) torch.Size([786, 90]) torch.Size([153, 90]) torch.Size([841, 90]) torch.Size([164, 90]) torch.Size([756, 90]) torch.Size([147, 90]) torch.Size([756, 90]) torch.Size([147, 90]) torch.Size([871, 90]) torch.Size([170, 90]) torch.Size([941, 90]) torch.Size([184, 90]) torch.Size([771, 90]) torch.Size([150, 90]) torch.Size([1076, 90]) torch.Size([211, 90]) torch.Size([771, 90]) torch.Size([150, 90]) torch.Size([1026, 90]) torch.Size([201, 90]) torch.Size([1041, 90]) torch.Size([204, 90]) torch.Size([836, 90]) torch.Size([163, 90]) torch.Size([961, 90]) torch.Size([188, 90]) torch.Size([606, 90]) torch.Size([117, 90]) torch.Size([786, 90]) torch.Size([153, 90]) torch.Size([836, 90]) torch.Size([163, 90]) torch.Size([1076, 90]) torch.Size([211, 90]) torch.Size([976, 90]) torch.Size([191, 90]) torch.Size([876, 90]) torch.Size([171, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([601, 90]) torch.Size([116, 90]) torch.Size([941, 90]) torch.Size([184, 90]) torch.Size([856, 90]) torch.Size([167, 90]) torch.Size([906, 90]) torch.Size([177, 90]) torch.Size([1196, 90]) torch.Size([235, 90]) torch.Size([636, 90]) torch.Size([123, 90]) torch.Size([776, 90]) torch.Size([151, 90]) torch.Size([856, 90]) torch.Size([167, 90]) torch.Size([976, 90]) torch.Size([191, 90]) torch.Size([941, 90]) torch.Size([184, 90]) torch.Size([991, 90]) torch.Size([194, 90]) torch.Size([1011, 90]) torch.Size([198, 90]) torch.Size([706, 90]) torch.Size([137, 90]) torch.Size([741, 90]) torch.Size([144, 90]) torch.Size([991, 90]) torch.Size([194, 90]) torch.Size([1011, 90]) torch.Size([198, 90]) torch.Size([776, 90]) torch.Size([151, 90]) torch.Size([721, 90]) torch.Size([140, 90]) torch.Size([1176, 90]) torch.Size([231, 90]) torch.Size([651, 90]) torch.Size([126, 90]) torch.Size([771, 90]) torch.Size([150, 90]) torch.Size([841, 90]) torch.Size([164, 90]) torch.Size([1076, 90]) torch.Size([211, 90]) torch.Size([736, 90]) torch.Size([143, 90]) torch.Size([756, 90]) torch.Size([147, 90]) torch.Size([941, 90]) torch.Size([184, 90]) torch.Size([976, 90]) torch.Size([191, 90]) torch.Size([691, 90]) torch.Size([134, 90]) torch.Size([876, 90]) torch.Size([171, 90]) torch.Size([841, 90]) torch.Size([164, 90]) torch.Size([1081, 90]) torch.Size([212, 90]) torch.Size([956, 90]) torch.Size([187, 90]) torch.Size([1046, 90]) torch.Size([205, 90]) torch.Size([551, 90]) torch.Size([106, 90]) torch.Size([891, 90]) torch.Size([174, 90]) torch.Size([821, 90]) torch.Size([160, 90]) torch.Size([986, 90]) torch.Size([193, 90]) torch.Size([1061, 90]) torch.Size([208, 90]) torch.Size([961, 90]) torch.Size([188, 90]) torch.Size([786, 90]) torch.Size([153, 90]) torch.Size([736, 90]) torch.Size([143, 90]) torch.Size([1636, 90]) torch.Size([323, 90]) torch.Size([876, 90]) torch.Size([171, 90]) torch.Size([1126, 90]) torch.Size([221, 90]) torch.Size([821, 90]) torch.Size([160, 90]) torch.Size([991, 90]) torch.Size([194, 90]) torch.Size([701, 90]) torch.Size([136, 90]) torch.Size([891, 90]) torch.Size([174, 90]) torch.Size([976, 90]) torch.Size([191, 90]) activity: standup nData: 79\n",
      "torch.Size([2976, 90]) torch.Size([591, 90]) torch.Size([3586, 90]) torch.Size([713, 90]) torch.Size([4196, 90]) torch.Size([835, 90]) torch.Size([4821, 90]) torch.Size([960, 90]) torch.Size([4941, 90]) torch.Size([984, 90]) torch.Size([3381, 90]) torch.Size([672, 90]) torch.Size([4486, 90]) torch.Size([893, 90]) torch.Size([3026, 90]) torch.Size([601, 90]) torch.Size([4231, 90]) torch.Size([842, 90]) torch.Size([3446, 90]) torch.Size([685, 90]) torch.Size([4701, 90]) torch.Size([936, 90]) torch.Size([3041, 90]) torch.Size([604, 90]) torch.Size([3091, 90]) torch.Size([614, 90]) torch.Size([4181, 90]) torch.Size([832, 90]) torch.Size([4361, 90]) torch.Size([868, 90]) torch.Size([2891, 90]) torch.Size([574, 90]) torch.Size([4856, 90]) torch.Size([967, 90]) torch.Size([3566, 90]) torch.Size([709, 90]) torch.Size([3836, 90]) torch.Size([763, 90]) torch.Size([2856, 90]) torch.Size([567, 90]) torch.Size([3126, 90]) torch.Size([621, 90]) torch.Size([3076, 90]) torch.Size([611, 90]) torch.Size([3566, 90]) torch.Size([709, 90]) torch.Size([3741, 90]) torch.Size([744, 90]) torch.Size([3416, 90]) torch.Size([679, 90]) torch.Size([3736, 90]) torch.Size([743, 90]) torch.Size([3686, 90]) torch.Size([733, 90]) torch.Size([3651, 90]) torch.Size([726, 90]) torch.Size([3891, 90]) torch.Size([774, 90]) torch.Size([3351, 90]) torch.Size([666, 90]) torch.Size([3771, 90]) torch.Size([750, 90]) torch.Size([3721, 90]) torch.Size([740, 90]) torch.Size([4601, 90]) torch.Size([916, 90]) torch.Size([3671, 90]) torch.Size([730, 90]) torch.Size([3836, 90]) torch.Size([763, 90]) torch.Size([4211, 90]) torch.Size([838, 90]) torch.Size([2741, 90]) torch.Size([544, 90]) torch.Size([4806, 90]) torch.Size([957, 90]) torch.Size([3906, 90]) torch.Size([777, 90]) torch.Size([4856, 90]) torch.Size([967, 90]) torch.Size([3091, 90]) torch.Size([614, 90]) torch.Size([4531, 90]) torch.Size([902, 90]) torch.Size([3161, 90]) torch.Size([628, 90]) torch.Size([3616, 90]) torch.Size([719, 90]) torch.Size([4361, 90]) torch.Size([868, 90]) torch.Size([5026, 90]) torch.Size([1001, 90]) torch.Size([3701, 90]) torch.Size([736, 90]) torch.Size([4011, 90]) torch.Size([798, 90]) torch.Size([4536, 90]) torch.Size([903, 90]) torch.Size([2996, 90]) torch.Size([595, 90]) torch.Size([4311, 90]) torch.Size([858, 90]) torch.Size([3736, 90]) torch.Size([743, 90]) torch.Size([3756, 90]) torch.Size([747, 90]) torch.Size([3841, 90]) torch.Size([764, 90]) torch.Size([4161, 90]) torch.Size([828, 90]) torch.Size([3266, 90]) torch.Size([649, 90]) torch.Size([3701, 90]) torch.Size([736, 90]) torch.Size([4296, 90]) torch.Size([855, 90]) torch.Size([3806, 90]) torch.Size([757, 90]) torch.Size([3906, 90]) torch.Size([777, 90]) torch.Size([3061, 90]) torch.Size([608, 90]) torch.Size([3291, 90]) torch.Size([654, 90]) torch.Size([3096, 90]) torch.Size([615, 90]) torch.Size([3026, 90]) torch.Size([601, 90]) torch.Size([4161, 90]) torch.Size([828, 90]) torch.Size([4431, 90]) torch.Size([882, 90]) torch.Size([2771, 90]) torch.Size([550, 90]) torch.Size([3736, 90]) torch.Size([743, 90]) torch.Size([3366, 90]) torch.Size([669, 90]) torch.Size([3111, 90]) torch.Size([618, 90]) torch.Size([3756, 90]) torch.Size([747, 90]) torch.Size([4586, 90]) torch.Size([913, 90]) torch.Size([2836, 90]) torch.Size([563, 90]) torch.Size([3091, 90]) torch.Size([614, 90]) torch.Size([3471, 90]) torch.Size([690, 90]) torch.Size([4566, 90]) torch.Size([909, 90]) torch.Size([4856, 90]) torch.Size([967, 90]) torch.Size([4046, 90]) torch.Size([805, 90]) torch.Size([3471, 90]) torch.Size([690, 90]) torch.Size([4976, 90]) torch.Size([991, 90]) activity: walk nData: 80\n"
     ]
    }
   ],
   "source": [
    "inputJsonFileName = 'test'\n",
    "LSTMModelDir = './savedModels/selected/'\n",
    "\n",
    "inputJsonFile = open(\"./inputJson/varGAIL/\" + inputJsonFileName + \".json\", \"r\")\n",
    "inputJson = json.load(inputJsonFile)\n",
    "LSTMTargetModelName = inputJson['LSTMTargetModelName']\n",
    "LSTMSurroModelName = inputJson['LSTMSurroModelName']\n",
    "noiseAmpRatio = inputJson['noiseAmpRatio']\n",
    "trDataList = inputJson['trDataList']\n",
    "trExpDataRatio = inputJson['trExpDataRatio']\n",
    "nHiddenGAIL = inputJson['nHiddenGAIL']\n",
    "padLen = inputJson['padLen']\n",
    "inputLenTime = inputJson['inputLenTime']\n",
    "outputLenTime = inputJson['outputLenTime']\n",
    "dSampFactor = inputJson['dSampFactor']\n",
    "delayLen = inputJson['delayLen']\n",
    "GAILTrainConfig = inputJson['trainConfig']\n",
    "print(dSampFactor, padLen)\n",
    "\n",
    "cudaID = 5\n",
    "attackScheme = 'GAIL'\n",
    "\n",
    "# padLen = 9\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "if cudaID >= 0:\n",
    "    device = torch.device(\"cuda:\"+str(cudaID))\n",
    "    cudaAvbl = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    cudaAvbl = False\n",
    "cudaLoc = 'cuda:' + str(cudaID)\n",
    "\n",
    "dataType = LSTMTargetModelName.split('_')[0]\n",
    "if dataType == 'TAR':\n",
    "    fs = 1000 # 1 kHz\n",
    "    nSubC = 30\n",
    "    nRX = 3\n",
    "    \n",
    "    winLen = 1000\n",
    "    activities = ['bed', 'fall', 'run', 'sitdown', 'standup', 'walk']\n",
    "    # activities = ['bed', 'fall', 'run', 'sitdown', 'standup', 'walk']\n",
    "\n",
    "    targetSingleAct = True\n",
    "    testAct = ['bed', 'fall', 'run', 'sitdown', 'standup', 'walk']\n",
    "\n",
    "print(LSTMSurroModelName, LSTMTargetModelName)\n",
    "LSTMTargetType = LSTMTargetModelName.split('_')[2]\n",
    "biDirTarget = (LSTMTargetType == 'BiLSTM')\n",
    "LSTMSurroType = LSTMSurroModelName.split('_')[1]\n",
    "biDirSurro = (LSTMSurroType == 'BiLSTM')\n",
    "nHiddenTarget = int(LSTMTargetModelName.split('_')[4])\n",
    "nHiddenSurro = int(LSTMSurroModelName.split('_')[3])\n",
    "# nLayer = int(LSTMModelName.split('_')[7])\n",
    "targetWin = (LSTMTargetModelName.split('_')[5] == 'win')\n",
    "saveFileName = LSTMSurroModelName + '_' + inputJsonFileName\n",
    "\n",
    "# Load target/surro LSTM models\n",
    "if targetWin:\n",
    "    HARTargetNet = LSTMNet_TAR(nClasses=len(activities),\\\n",
    "                    input_size=nSubC*nRX,\\\n",
    "                    bidirectional=biDirTarget,\\\n",
    "                    hidden_size=nHiddenTarget,\\\n",
    "                    num_layers=1,\\\n",
    "                    seq_length=1000,\\\n",
    "                    device=device)\n",
    "    dSampRatio = 5\n",
    "else:\n",
    "    HARTargetNet = VariableLSTMNet(nClasses=len(activities),\\\n",
    "                    input_size=nSubC*nRX,\\\n",
    "                    bidirectional=biDirTarget,\\\n",
    "                    hidden_size=nHiddenTarget,\\\n",
    "                    num_layers=1,\\\n",
    "                    device=device)\n",
    "HARTargetNet.load_state_dict(torch.load(LSTMModelDir + LSTMTargetModelName + '.cpkt', map_location=cudaLoc))\n",
    "\n",
    "HARSurroNet = VariableLSTMNet(nClasses=len(activities),\\\n",
    "                input_size=nSubC*nRX,\\\n",
    "                bidirectional=biDirSurro,\\\n",
    "                hidden_size=nHiddenSurro,\\\n",
    "                num_layers=1,\\\n",
    "                device=device)\n",
    "HARSurroNet.load_state_dict(torch.load(LSTMModelDir + LSTMSurroModelName + '.cpkt', map_location=cudaLoc))\n",
    "\n",
    "# HARNet.to(device)\n",
    "\n",
    "# Load dataset labelled with FGM attack\n",
    "FGMdatasetDir = '/project/iarpa/wifiHAR/HAR_' + dataType + '/noWin_dSamp_' + str(dSampFactor) + '_pad_' + str(padLen) + '_FGM/'\n",
    "dataDict = {file:[] for file in activities}\n",
    "# tsDataDict = {file:[] for file in activities}\n",
    "\n",
    "trDataset = list()\n",
    "tsDataset = list()\n",
    "correct = 0.0\n",
    "nData = 0.0\n",
    "noiseAmpRatio = 1e-4\n",
    "# activities = ['walk']\n",
    "longestLenList = list()\n",
    "for actIdx, activity in enumerate(activities):\n",
    "    longestLen = 0\n",
    "    dataDict[activity] = defaultdict(list)\n",
    "\n",
    "    dataInputActFileName = FGMdatasetDir + 'input_' + LSTMSurroModelName + '_' + activity + '.npy'\n",
    "    dataFGMActFileName = FGMdatasetDir + 'FGM_' + LSTMSurroModelName + '_' + activity + '.npy'\n",
    "\n",
    "    datasetObs = np.load(dataInputActFileName, allow_pickle=True)\n",
    "    datasetFGM = np.load(dataFGMActFileName, allow_pickle=True)\n",
    "    dSampRatio = 1\n",
    "    for (ob, FGM) in zip(datasetObs, datasetFGM):\n",
    "        print(ob[::dSampRatio, :].shape, FGM.shape, end=' ')\n",
    "        # print(ob.shape, FGM.shape, end=' ')\n",
    "        dataDict[activity]['input'].append(ob[::dSampRatio, :])\n",
    "        dataDict[activity]['FGM'].append(FGM)\n",
    "    dataDict[activity]['label'] = actIdx*torch.ones(len(dataDict[activity]['input']), dtype=int, device=device)\n",
    "\n",
    "    # for i in range(0, ob.shape[0], inputLenTime*dSampRatio):\n",
    "    #     # print(i, end=' ')\n",
    "    #     if i+inputLenTime*dSampRatio > ob.shape[0]:\n",
    "    #         break\n",
    "    #     dataDict[activity]['input'].append(ob[i:i+inputLenTime*dSampRatio:dSampRatio, :])\n",
    "    #     dataDict[activity]['label'].append(FGM[(i//dSampRatio), :])\n",
    "    # longestLenList.append(longestLen)\n",
    "            \n",
    "    print('activity:', activity, 'nData:', len(dataDict[activity]['input']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSI_BCDataset(Dataset):\n",
    "    def __init__(self, dataDict, device, normalize=False, nSubC=1, nRX=1, padLen=0):\n",
    "        self.features = dataDict['input'] # using IQ sample value\n",
    "        self.FGM = dataDict['FGM']\n",
    "        self.labels = dataDict['label']\n",
    "        self.device = device\n",
    "        self.normalize = normalize\n",
    "        self.nSubC = nSubC\n",
    "        self.nRX = nRX\n",
    "        self.padLen = padLen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        data = torch.tensor(self.features[idx], device=self.device).float()\n",
    "        # print('what', data.shape)\n",
    "        data = data[self.padLen:, :]\n",
    "        FGM = torch.tensor(self.FGM[idx], device=self.device).float()\n",
    "        if self.normalize:\n",
    "            data = data * torch.numel(data) /\\\n",
    "                (LA.norm(data) * self.nSubC * self.nRX)\n",
    "            FGM = FGM * torch.numel(FGM) /\\\n",
    "                (LA.norm(FGM) * self.nSubC * self.nRX)\n",
    "        # print(LA.norm(data))\n",
    "\n",
    "        label = torch.tensor(self.labels[idx], device=self.device).long()\n",
    "        return {'input': data, 'label': label, 'FGM': FGM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed 39 40 79\n",
      "fall 39 40 79\n",
      "run 39 40 80\n",
      "sitdown 39 40 80\n",
      "standup 39 40 79\n",
      "walk 39 40 80\n",
      "# of tr data: 234 # of ts data: 240\n"
     ]
    }
   ],
   "source": [
    "trData = list()\n",
    "tsData = list()\n",
    "for actIndex, activity in enumerate(activities):\n",
    "    dataset = CSI_BCDataset(dataDict[activity],\\\n",
    "                    device,\\\n",
    "                    normalize=True,\\\n",
    "                    nSubC=nSubC,\\\n",
    "                    nRX=nRX,\\\n",
    "                    padLen=0)\n",
    "    if actIndex == 0:\n",
    "        tsDataList = [0, 1, 3, 4, 7, 10, 11, 13, 14, 15, 21, 22, 24, 27, 28, 29, 30, 32, 39, 40,\\\n",
    "            41, 42, 43, 46, 49, 52, 53, 55, 59, 60, 61, 62, 63, 67, 68, 69, 70, 73, 76, 78]\n",
    "        trDataList = list(set(range(len(dataset))) - set(tsDataList))\n",
    "\n",
    "    trData.append(torch.utils.data.Subset(dataset, trDataList))\n",
    "    tsData.append(torch.utils.data.Subset(dataset, tsDataList))\n",
    "    print(activity, len(trDataList), len(tsDataList), len(dataset))\n",
    "\n",
    "trDataset = torch.utils.data.ConcatDataset(trData) # concatenating dataset lists\n",
    "tsDataset = torch.utils.data.ConcatDataset(tsData)\n",
    "print(\"# of tr data:\", len(trDataset), \"# of ts data:\", len(tsDataset))\n",
    "\n",
    "batchSize = 1\n",
    "trLoader = DataLoader(trDataset, batch_size=batchSize, shuffle=False, collate_fn=collate_fn_FGM)\n",
    "tsLoader = DataLoader(tsDataset, batch_size=batchSize, shuffle=False, collate_fn=collate_fn_FGM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_BC(nn.Module):\n",
    "    def __init__(self, input_size, output_size, bidirectional, hidden_size, num_layers, seq_length, device):\n",
    "        super(LSTM_BC, self).__init__()\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.output_size = output_size #output size\n",
    "        self.bidirectional = bidirectional #flag indicating whether LSTM is bidirectional\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "        self.device = device\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\\\n",
    "                            hidden_size=hidden_size,\\\n",
    "                            num_layers=num_layers,\\\n",
    "                            batch_first=True,\\\n",
    "                            bidirectional=bidirectional,\\\n",
    "                            device=self.device) #lstm\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(2*hidden_size*seq_length, output_size, device=self.device) #fully connected last layer\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size*seq_length, output_size, device=self.device) #fully connected last layer\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        if self.bidirectional:\n",
    "            h_0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(self.device) #hidden state\n",
    "            c_0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(self.device) #internal state\n",
    "        else:\n",
    "            h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device) #hidden state\n",
    "            c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device) #internal state\n",
    "            \n",
    "        # Propagate input through LSTM\n",
    "        hi, (hn, _) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hi = hi.reshape(hi.shape[0], -1) #reshaping the data for Dense layer next\n",
    "\n",
    "        out = self.relu(hi)\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAR_BiLSTM_H_200_dS_10\n",
      "234 240\n"
     ]
    }
   ],
   "source": [
    "LSTM_BCLoss = torch.nn.MSELoss()\n",
    "bidirectional = True\n",
    "nHidden = 200\n",
    "maxPatience = 40\n",
    "LR = 2e-4\n",
    "nEpoch = 400\n",
    "\n",
    "fromInit = False\n",
    "print(LSTMSurroModelName)\n",
    "HARNetSavePath = './savedModels/varGAIL/TAR_BiLSTM_H_200_dS_10_nH_200_dS_10_LR_1e-5_dLen_1_iL_5_BC.cpkt' \n",
    "\n",
    "print(len(trLoader), len(tsLoader))\n",
    "HARNet_BC = LSTM_BC(input_size=nSubC*nRX,\\\n",
    "                output_size=nSubC*nRX,\\\n",
    "                bidirectional=bidirectional,\\\n",
    "                hidden_size=nHidden,\\\n",
    "                num_layers=1,\\\n",
    "                seq_length=5,\\\n",
    "                device=device)\n",
    "HARNet_BC.to(device)\n",
    "\n",
    "if fromInit:\n",
    "    HARNet_BC.apply(init_weights)\n",
    "else:\n",
    "    HARNet_BC.load_state_dict(torch.load(HARNetSavePath))\n",
    "opt = torch.optim.Adam(HARNet_BC.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model path: ./savedModels/varGAIL/TAR_BiLSTM_H_200_dS_10_nH_200_dS_10_LR_1e-5_dLen_1_iL_5_BC.cpkt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1602887/1903631498.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.features[idx], device=self.device).float()\n",
      "/tmp/ipykernel_1602887/1903631498.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  FGM = torch.tensor(self.FGM[idx], device=self.device).float()\n",
      "/tmp/ipykernel_1602887/1903631498.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], device=self.device).long()\n",
      "/home/byk004/24-RT_adv_HAR/utilities.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs],\n",
      "/home/byk004/24-RT_adv_HAR/utilities.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  FGM_padded = pad_sequence([torch.tensor(seq_FGM) for seq_FGM in FGMs],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, trLoss: 0.068574, tsLoss: 0.072071 saving model  \n",
      "Epoch: 1, trLoss: 0.068488, tsLoss: 0.072208  \n",
      "Epoch: 2, trLoss: 0.068388, tsLoss: 0.072358  \n",
      "Epoch: 3, trLoss: 0.068354, tsLoss: 0.072336  \n",
      "Epoch: 4, trLoss: 0.068337, tsLoss: 0.072394  \n",
      "Epoch: 5, trLoss: 0.068309, tsLoss: 0.072415  \n",
      "Epoch: 6, trLoss: 0.068217, tsLoss: 0.072528  \n",
      "Epoch: 7, trLoss: 0.068201, tsLoss: 0.072539  \n",
      "Epoch: 8, trLoss: 0.068102, tsLoss: 0.072543  \n",
      "Epoch: 9, trLoss: 0.068081, tsLoss: 0.072756  \n",
      "Epoch: 10, trLoss: 0.068060, tsLoss: 0.072655  \n",
      "Epoch: 11, trLoss: 0.068008, tsLoss: 0.072802  \n",
      "Epoch: 12, trLoss: 0.067952, tsLoss: 0.072822  \n",
      "Epoch: 13, trLoss: 0.067973, tsLoss: 0.072968  \n",
      "Epoch: 14, trLoss: 0.067918, tsLoss: 0.072944  \n",
      "Epoch: 15, trLoss: 0.067935, tsLoss: 0.072838  \n",
      "Epoch: 16, trLoss: 0.067878, tsLoss: 0.072758  \n",
      "Epoch: 17, trLoss: 0.067826, tsLoss: 0.072833  \n",
      "Epoch: 18, trLoss: 0.067794, tsLoss: 0.072831  \n",
      "Epoch: 19, trLoss: 0.067735, tsLoss: 0.072824  \n",
      "Epoch: 20, trLoss: 0.067636, tsLoss: 0.072780  \n",
      "Epoch: 21, trLoss: 0.067559, tsLoss: 0.072766  \n",
      "Epoch: 22, trLoss: 0.067518, tsLoss: 0.072770  \n",
      "Epoch: 23, trLoss: 0.067513, tsLoss: 0.072854  \n",
      "Epoch: 24, trLoss: 0.067457, tsLoss: 0.072802  \n",
      "Epoch: 25, trLoss: 0.067430, tsLoss: 0.072832  \n",
      "Epoch: 26, trLoss: 0.067323, tsLoss: 0.072919  \n",
      "Epoch: 27, trLoss: 0.067237, tsLoss: 0.072998  \n",
      "Epoch: 28, trLoss: 0.067167, tsLoss: 0.072998  \n",
      "Epoch: 29, trLoss: 0.067133, tsLoss: 0.073005  \n",
      "Epoch: 30, trLoss: 0.067125, tsLoss: 0.073138  \n",
      "Epoch: 31, trLoss: 0.067112, tsLoss: 0.073123  \n",
      "Epoch: 32, trLoss: 0.067076, tsLoss: 0.073265  \n",
      "Epoch: 33, trLoss: 0.067066, tsLoss: 0.073251  \n",
      "Epoch: 34, trLoss: 0.067059, tsLoss: 0.073369  \n",
      "Epoch: 35, trLoss: 0.067083, tsLoss: 0.073503  \n",
      "Epoch: 36, trLoss: 0.067007, tsLoss: 0.073530  \n",
      "Epoch: 37, trLoss: 0.066929, tsLoss: 0.073489  \n",
      "Epoch: 38, trLoss: 0.066843, tsLoss: 0.073601  \n",
      "Epoch: 39, trLoss: 0.066879, tsLoss: 0.073664  \n",
      "Epoch: 40, trLoss: 0.066882, tsLoss: 0.073584 fast convergence ends  \n",
      "Epoch: 41, trLoss: 0.068134, tsLoss: 0.071272 saving model  \n",
      "Epoch: 42, trLoss: 0.067783, tsLoss: 0.071224 saving model  \n",
      "Epoch: 43, trLoss: 0.067640, tsLoss: 0.071201 saving model  \n",
      "Epoch: 44, trLoss: 0.067557, tsLoss: 0.071189 saving model  \n",
      "Epoch: 45, trLoss: 0.067507, tsLoss: 0.071185 saving model  \n",
      "Epoch: 46, trLoss: 0.067475, tsLoss: 0.071185  \n",
      "Epoch: 47, trLoss: 0.067449, tsLoss: 0.071183 saving model  \n",
      "Epoch: 48, trLoss: 0.067425, tsLoss: 0.071181 saving model  \n",
      "Epoch: 49, trLoss: 0.067405, tsLoss: 0.071180 saving model  \n",
      "Epoch: 50, trLoss: 0.067386, tsLoss: 0.071180 saving model  \n",
      "Epoch: 51, trLoss: 0.067370, tsLoss: 0.071180 saving model  \n",
      "Epoch: 52, trLoss: 0.067353, tsLoss: 0.071179 saving model  \n",
      "Epoch: 53, trLoss: 0.067338, tsLoss: 0.071179 saving model  \n",
      "Epoch: 54, trLoss: 0.067323, tsLoss: 0.071179 saving model  \n",
      "Epoch: 55, trLoss: 0.067309, tsLoss: 0.071178 saving model  \n",
      "Epoch: 56, trLoss: 0.067294, tsLoss: 0.071179  \n",
      "Epoch: 57, trLoss: 0.067280, tsLoss: 0.071178  \n",
      "Epoch: 58, trLoss: 0.067267, tsLoss: 0.071177 saving model  \n",
      "Epoch: 59, trLoss: 0.067253, tsLoss: 0.071178  \n",
      "Epoch: 60, trLoss: 0.067240, tsLoss: 0.071177 saving model  \n",
      "Epoch: 61, trLoss: 0.067227, tsLoss: 0.071177  \n",
      "Epoch: 62, trLoss: 0.067214, tsLoss: 0.071177  \n",
      "Epoch: 63, trLoss: 0.067202, tsLoss: 0.071176 saving model  \n",
      "Epoch: 64, trLoss: 0.067188, tsLoss: 0.071176  \n",
      "Epoch: 65, trLoss: 0.067176, tsLoss: 0.071175 saving model  \n",
      "Epoch: 66, trLoss: 0.067163, tsLoss: 0.071175  \n",
      "Epoch: 67, trLoss: 0.067150, tsLoss: 0.071175 saving model  \n",
      "Epoch: 68, trLoss: 0.067138, tsLoss: 0.071174 saving model  \n",
      "Epoch: 69, trLoss: 0.067125, tsLoss: 0.071174 saving model  \n",
      "Epoch: 70, trLoss: 0.067112, tsLoss: 0.071173 saving model  \n",
      "Epoch: 71, trLoss: 0.067100, tsLoss: 0.071172 saving model  \n",
      "Epoch: 72, trLoss: 0.067088, tsLoss: 0.071171 saving model  \n",
      "Epoch: 73, trLoss: 0.067076, tsLoss: 0.071171 saving model  \n",
      "Epoch: 74, trLoss: 0.067063, tsLoss: 0.071173  \n",
      "Epoch: 75, trLoss: 0.067051, tsLoss: 0.071171 saving model  \n",
      "Epoch: 76, trLoss: 0.067038, tsLoss: 0.071172  \n",
      "Epoch: 77, trLoss: 0.067026, tsLoss: 0.071172  \n",
      "Epoch: 78, trLoss: 0.067014, tsLoss: 0.071171  \n",
      "Epoch: 79, trLoss: 0.067002, tsLoss: 0.071171  \n",
      "Epoch: 80, trLoss: 0.066991, tsLoss: 0.071171  \n",
      "Epoch: 81, trLoss: 0.066978, tsLoss: 0.071171 saving model  \n",
      "Epoch: 82, trLoss: 0.066966, tsLoss: 0.071171 saving model  \n",
      "Epoch: 83, trLoss: 0.066954, tsLoss: 0.071170 saving model  \n",
      "Epoch: 84, trLoss: 0.066942, tsLoss: 0.071170 saving model  \n",
      "Epoch: 85, trLoss: 0.066930, tsLoss: 0.071172  \n",
      "Epoch: 86, trLoss: 0.066919, tsLoss: 0.071172  \n",
      "Epoch: 87, trLoss: 0.066907, tsLoss: 0.071171  \n",
      "Epoch: 88, trLoss: 0.066895, tsLoss: 0.071172  \n",
      "Epoch: 89, trLoss: 0.066883, tsLoss: 0.071172  \n",
      "Epoch: 90, trLoss: 0.066871, tsLoss: 0.071171  \n",
      "Epoch: 91, trLoss: 0.066859, tsLoss: 0.071171  \n",
      "Epoch: 92, trLoss: 0.066848, tsLoss: 0.071171  \n",
      "Epoch: 93, trLoss: 0.066836, tsLoss: 0.071171  \n",
      "Epoch: 94, trLoss: 0.066825, tsLoss: 0.071171  \n",
      "Epoch: 95, trLoss: 0.066813, tsLoss: 0.071170 saving model  \n",
      "Epoch: 96, trLoss: 0.066801, tsLoss: 0.071169 saving model  \n",
      "Epoch: 97, trLoss: 0.066789, tsLoss: 0.071170  \n",
      "Epoch: 98, trLoss: 0.066778, tsLoss: 0.071169 saving model  \n",
      "Epoch: 99, trLoss: 0.066767, tsLoss: 0.071168 saving model  \n",
      "Epoch: 100, trLoss: 0.066755, tsLoss: 0.071169  \n",
      "Epoch: 101, trLoss: 0.066744, tsLoss: 0.071168 saving model  \n",
      "Epoch: 102, trLoss: 0.066732, tsLoss: 0.071169  \n",
      "Epoch: 103, trLoss: 0.066721, tsLoss: 0.071166 saving model  \n",
      "Epoch: 104, trLoss: 0.066710, tsLoss: 0.071166 saving model  \n",
      "Epoch: 105, trLoss: 0.066699, tsLoss: 0.071167  \n",
      "Epoch: 106, trLoss: 0.066687, tsLoss: 0.071166 saving model  \n",
      "Epoch: 107, trLoss: 0.066676, tsLoss: 0.071166  \n",
      "Epoch: 108, trLoss: 0.066664, tsLoss: 0.071166  \n",
      "Epoch: 109, trLoss: 0.066652, tsLoss: 0.071165 saving model  \n",
      "Epoch: 110, trLoss: 0.066642, tsLoss: 0.071166  \n",
      "Epoch: 111, trLoss: 0.066631, tsLoss: 0.071165 saving model  \n",
      "Epoch: 112, trLoss: 0.066620, tsLoss: 0.071165  \n",
      "Epoch: 113, trLoss: 0.066608, tsLoss: 0.071165  \n",
      "Epoch: 114, trLoss: 0.066596, tsLoss: 0.071164 saving model  \n",
      "Epoch: 115, trLoss: 0.066585, tsLoss: 0.071166  \n",
      "Epoch: 116, trLoss: 0.066574, tsLoss: 0.071164 saving model  \n",
      "Epoch: 117, trLoss: 0.066563, tsLoss: 0.071164 saving model  \n",
      "Epoch: 118, trLoss: 0.066552, tsLoss: 0.071164  \n",
      "Epoch: 119, trLoss: 0.066540, tsLoss: 0.071163 saving model  \n",
      "Epoch: 120, trLoss: 0.066530, tsLoss: 0.071164  \n",
      "Epoch: 121, trLoss: 0.066519, tsLoss: 0.071164  \n",
      "Epoch: 122, trLoss: 0.066508, tsLoss: 0.071164  \n",
      "Epoch: 123, trLoss: 0.066497, tsLoss: 0.071162 saving model  \n",
      "Epoch: 124, trLoss: 0.066486, tsLoss: 0.071162  \n",
      "Epoch: 125, trLoss: 0.066475, tsLoss: 0.071162  \n",
      "Epoch: 126, trLoss: 0.066463, tsLoss: 0.071161 saving model  \n",
      "Epoch: 127, trLoss: 0.066452, tsLoss: 0.071161  \n",
      "Epoch: 128, trLoss: 0.066442, tsLoss: 0.071159 saving model  \n",
      "Epoch: 129, trLoss: 0.066430, tsLoss: 0.071158 saving model  \n",
      "Epoch: 130, trLoss: 0.066420, tsLoss: 0.071157 saving model  \n",
      "Epoch: 131, trLoss: 0.066408, tsLoss: 0.071159  \n",
      "Epoch: 132, trLoss: 0.066398, tsLoss: 0.071159  \n",
      "Epoch: 133, trLoss: 0.066386, tsLoss: 0.071159  \n",
      "Epoch: 134, trLoss: 0.066376, tsLoss: 0.071159  \n",
      "Epoch: 135, trLoss: 0.066364, tsLoss: 0.071158  \n",
      "Epoch: 136, trLoss: 0.066353, tsLoss: 0.071159  \n",
      "Epoch: 137, trLoss: 0.066342, tsLoss: 0.071158  \n",
      "Epoch: 138, trLoss: 0.066332, tsLoss: 0.071158  \n",
      "Epoch: 139, trLoss: 0.066321, tsLoss: 0.071156 saving model  \n",
      "Epoch: 140, trLoss: 0.066311, tsLoss: 0.071156 saving model  \n",
      "Epoch: 141, trLoss: 0.066300, tsLoss: 0.071156 saving model  \n",
      "Epoch: 142, trLoss: 0.066289, tsLoss: 0.071156  \n",
      "Epoch: 143, trLoss: 0.066279, tsLoss: 0.071155 saving model  \n",
      "Epoch: 144, trLoss: 0.066269, tsLoss: 0.071156  \n",
      "Epoch: 145, trLoss: 0.066258, tsLoss: 0.071156  \n",
      "Epoch: 146, trLoss: 0.066247, tsLoss: 0.071156  \n",
      "Epoch: 147, trLoss: 0.066236, tsLoss: 0.071156  \n",
      "Epoch: 148, trLoss: 0.066226, tsLoss: 0.071156  \n",
      "Epoch: 149, trLoss: 0.066215, tsLoss: 0.071155 saving model  \n",
      "Epoch: 150, trLoss: 0.066204, tsLoss: 0.071154 saving model  \n",
      "Epoch: 151, trLoss: 0.066194, tsLoss: 0.071154 saving model  \n",
      "Epoch: 152, trLoss: 0.066183, tsLoss: 0.071154 saving model  \n",
      "Epoch: 153, trLoss: 0.066172, tsLoss: 0.071152 saving model  \n",
      "Epoch: 154, trLoss: 0.066161, tsLoss: 0.071153  \n",
      "Epoch: 155, trLoss: 0.066151, tsLoss: 0.071154  \n",
      "Epoch: 156, trLoss: 0.066140, tsLoss: 0.071153  \n",
      "Epoch: 157, trLoss: 0.066129, tsLoss: 0.071154  \n",
      "Epoch: 158, trLoss: 0.066118, tsLoss: 0.071155  \n",
      "Epoch: 159, trLoss: 0.066108, tsLoss: 0.071154  \n",
      "Epoch: 160, trLoss: 0.066097, tsLoss: 0.071152  \n",
      "Epoch: 161, trLoss: 0.066087, tsLoss: 0.071154  \n",
      "Epoch: 162, trLoss: 0.066077, tsLoss: 0.071155  \n",
      "Epoch: 163, trLoss: 0.066065, tsLoss: 0.071156  \n",
      "Epoch: 164, trLoss: 0.066055, tsLoss: 0.071155  \n",
      "Epoch: 165, trLoss: 0.066044, tsLoss: 0.071155  \n",
      "Epoch: 166, trLoss: 0.066034, tsLoss: 0.071155  \n",
      "Epoch: 167, trLoss: 0.066024, tsLoss: 0.071156  \n",
      "Epoch: 168, trLoss: 0.066013, tsLoss: 0.071156  \n",
      "Epoch: 169, trLoss: 0.066003, tsLoss: 0.071157  \n",
      "Epoch: 170, trLoss: 0.065992, tsLoss: 0.071157  \n",
      "Epoch: 171, trLoss: 0.065982, tsLoss: 0.071160  \n",
      "Epoch: 172, trLoss: 0.065972, tsLoss: 0.071158  \n",
      "Epoch: 173, trLoss: 0.065961, tsLoss: 0.071159  \n",
      "Epoch: 174, trLoss: 0.065951, tsLoss: 0.071158  \n",
      "Epoch: 175, trLoss: 0.065941, tsLoss: 0.071159  \n",
      "Epoch: 176, trLoss: 0.065930, tsLoss: 0.071160  \n",
      "Epoch: 177, trLoss: 0.065920, tsLoss: 0.071160  \n",
      "Epoch: 178, trLoss: 0.065909, tsLoss: 0.071160  \n",
      "Epoch: 179, trLoss: 0.065898, tsLoss: 0.071161  \n",
      "Epoch: 180, trLoss: 0.065888, tsLoss: 0.071163  \n",
      "Epoch: 181, trLoss: 0.065879, tsLoss: 0.071162  \n",
      "Epoch: 182, trLoss: 0.065868, tsLoss: 0.071163  \n",
      "Epoch: 183, trLoss: 0.065857, tsLoss: 0.071163  \n",
      "Epoch: 184, trLoss: 0.065847, tsLoss: 0.071164  \n",
      "Epoch: 185, trLoss: 0.065836, tsLoss: 0.071164  \n",
      "Epoch: 186, trLoss: 0.065827, tsLoss: 0.071165  \n",
      "Epoch: 187, trLoss: 0.065816, tsLoss: 0.071165  \n",
      "Epoch: 188, trLoss: 0.065805, tsLoss: 0.071164  \n",
      "Epoch: 189, trLoss: 0.065796, tsLoss: 0.071166  \n",
      "Epoch: 190, trLoss: 0.065785, tsLoss: 0.071166  \n",
      "Epoch: 191, trLoss: 0.065775, tsLoss: 0.071166  \n",
      "Epoch: 192, trLoss: 0.065765, tsLoss: 0.071167  \n",
      "Epoch: 193, trLoss: 0.065755, tsLoss: 0.071168 Training finished\n"
     ]
    }
   ],
   "source": [
    "bestLoss = 10.0\n",
    "patience = 0\n",
    "fastConvg = True\n",
    "# innerBatchSize = 100\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "print('save model path:', HARNetSavePath)\n",
    "for epoch in range(nEpoch):\n",
    "    runningLoss = 0.0\n",
    "    HARNet_BC.train()\n",
    "    nTrDataBC = 0\n",
    "    for trData in trLoader:\n",
    "        trInput, trLabel, trFGM = trData\n",
    "\n",
    "        trInputBatch = torch.empty((0, inputLenTime, nSubC*nRX)).to(device)\n",
    "        trFGMBatch = torch.empty((0, nSubC*nRX)).to(device)\n",
    "        for i in range(0, trFGM.shape[1], inputLenTime):\n",
    "            # print(i, end=' ')\n",
    "            trInputBatch = torch.cat((trInputBatch, trInput[:, i:i+inputLenTime, :]), 0)\n",
    "            trFGMBatch = torch.cat((trFGMBatch, trFGM[:, i, :]), 0)\n",
    "            nTrDataBC = nTrDataBC+1\n",
    "        # print(trInputBatch.shape, trFGMBatch.shape)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        trOutput = HARNet_BC(trInputBatch)\n",
    "        trloss = LSTM_BCLoss(trOutput, trFGMBatch)\n",
    "        trloss.backward()\n",
    "        opt.step()\n",
    "        runningLoss += trloss.item()\n",
    "\n",
    "    avgTrLoss = runningLoss / nTrDataBC\n",
    "    # accTrain = getAcc(trLoader, padLen, HARNet_BC, HARNet_BC, variableLen=True)\n",
    "\n",
    "    runningLoss = 0.0\n",
    "    nTsDataBC = 0\n",
    "    for tsData in tsLoader:\n",
    "        tsInput, tsLabel, tsFGM = tsData\n",
    "\n",
    "        tsInputBatch = torch.empty((0, inputLenTime, nSubC*nRX)).to(device)\n",
    "        tsFGMBatch = torch.empty((0, nSubC*nRX)).to(device)\n",
    "        for i in range(0, tsFGM.shape[1], inputLenTime):\n",
    "            tsInputBatch = torch.cat((tsInputBatch, tsInput[:, i:i+inputLenTime, :]), 0)\n",
    "            tsFGMBatch = torch.cat((tsFGMBatch, tsFGM[:, i, :]), 0)\n",
    "            nTsDataBC = nTsDataBC+1\n",
    "        # print(trInputBatch.shape, tsFGMBatch.shape)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        tsOutput = HARNet_BC(tsInputBatch)\n",
    "        tsloss = LSTM_BCLoss(tsOutput, tsFGMBatch)\n",
    "        runningLoss += tsloss.item()\n",
    "\n",
    "    avgTsLoss = runningLoss / nTsDataBC\n",
    "\n",
    "    print('Epoch: %d, trLoss: %.6f, tsLoss: %.6f'\\\n",
    "        % (epoch, avgTrLoss, avgTsLoss), end=' ')\n",
    "    if bestLoss > avgTsLoss:\n",
    "        bestLoss = avgTsLoss\n",
    "        print('saving model', end=' ')\n",
    "        torch.save(HARNet_BC.state_dict(), HARNetSavePath)  # saving model with best test accuracy\n",
    "        patience = 0\n",
    "\n",
    "    # print(trData.shape, trLabel.shape)\n",
    "    # early stopping if model converges twice\n",
    "    patience += 1\n",
    "    if patience > maxPatience:\n",
    "        if fastConvg:\n",
    "            LR = LR/10\n",
    "            opt = torch.optim.Adam(HARNet_BC.parameters(), lr=LR)\n",
    "            HARNet_BC.load_state_dict(torch.load(HARNetSavePath))\n",
    "            patience = 0\n",
    "            fastConvg = False\n",
    "            print('fast convergence ends', end=' ')\n",
    "        else:\n",
    "            break\n",
    "    print(' ')\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1592961/1903631498.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.features[idx], device=self.device).float()\n",
      "/tmp/ipykernel_1592961/1903631498.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  FGM = torch.tensor(self.FGM[idx], device=self.device).float()\n",
      "/tmp/ipykernel_1592961/1903631498.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], device=self.device).long()\n",
      "/home/byk004/24-RT_adv_HAR/utilities.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs],\n",
      "/home/byk004/24-RT_adv_HAR/utilities.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  FGM_padded = pad_sequence([torch.tensor(seq_FGM) for seq_FGM in FGMs],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9708333333333333\n"
     ]
    }
   ],
   "source": [
    "modelTargetName = 'TAR_BiLSTM_H_200_dS_10'\n",
    "HARNetTargetSavePath = './savedModels/selected/' + modelTargetName + \".cpkt\"\n",
    "\n",
    "biDirTarget = True\n",
    "HARNetTarget = VariableLSTMNet(nClasses=len(activities),\\\n",
    "                input_size=nSubC*nRX,\\\n",
    "                bidirectional=biDirTarget,\\\n",
    "                hidden_size=nHiddenTarget,\\\n",
    "                num_layers=1,\\\n",
    "                device=device)\n",
    "HARNetTarget.to(device)\n",
    "HARNetTarget.load_state_dict(torch.load(HARNetTargetSavePath))\n",
    "HARNetTarget.eval()\n",
    "\n",
    "noiseAmpRatio = 0.0\n",
    "accTest = getAcc(tsLoader,\\\n",
    "                padLen,\\\n",
    "                HARNetTarget,\\\n",
    "                HARNetTarget,\\\n",
    "                variableLen=True,\\\n",
    "                noiseAmpRatio=noiseAmpRatio,\\\n",
    "                noiseType='FGM')\n",
    "print(accTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMNet_TAR(\n",
       "  (lstm): LSTM(90, 200, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=400000, out_features=6, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nHiddenSurro = 200\n",
    "modelSurroName = 'TAR_BiLSTM_H_200_dS_10_nH_200_dS_10_LR_1e-5_dLen_1_iL_5_BC'\n",
    "HARNetSurroSavePath = './savedModels/selected/varGAIL/' + modelSurroName + \".cpkt\"\n",
    "biDirSurro = True\n",
    "\n",
    "nHiddenTarget = 200\n",
    "# modelTargetName = 'TAR_BiLSTM_H_200_dS_10'\n",
    "modelTargetName = 'TAR_target_BiLSTM_H_200_win'\n",
    "HARNetTargetSavePath = './savedModels/selected/' + modelTargetName + \".cpkt\"\n",
    "biDirTarget = True\n",
    "\n",
    "HARNetSurro = LSTM_BC(input_size=nSubC*nRX,\\\n",
    "                output_size=nSubC*nRX,\\\n",
    "                bidirectional=biDirSurro,\\\n",
    "                hidden_size=nHiddenSurro,\\\n",
    "                num_layers=1,\\\n",
    "                seq_length=5,\\\n",
    "                device=device)\n",
    "HARNetSurro.to(device)\n",
    "HARNetSurro.load_state_dict(torch.load(HARNetSurroSavePath))\n",
    "HARNetSurro.eval()\n",
    "\n",
    "# HARNetTarget = VariableLSTMNet(nClasses=len(activities),\\\n",
    "#                 input_size=nSubC*nRX,\\\n",
    "#                 bidirectional=biDirTarget,\\\n",
    "#                 hidden_size=nHiddenTarget,\\\n",
    "#                 num_layers=1,\\\n",
    "#                 device=device)\n",
    "\n",
    "HARNetTarget = LSTMNet_TAR(nClasses=len(activities),\\\n",
    "                input_size=nSubC*nRX,\\\n",
    "                bidirectional=biDirTarget,\\\n",
    "                hidden_size=nHiddenTarget,\\\n",
    "                num_layers=1,\\\n",
    "                seq_length=1000,\\\n",
    "                device=device)\n",
    "\n",
    "HARNetTarget.to(device)\n",
    "HARNetTarget.load_state_dict(torch.load(HARNetTargetSavePath))\n",
    "HARNetTarget.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1664864/1903631498.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.features[idx], device=self.device).float()\n",
      "/tmp/ipykernel_1664864/1903631498.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  FGM = torch.tensor(self.FGM[idx], device=self.device).float()\n",
      "/tmp/ipykernel_1664864/1903631498.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], device=self.device).long()\n",
      "/home/byk004/24-RT_adv_HAR/utilities.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs],\n",
      "/home/byk004/24-RT_adv_HAR/utilities.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  FGM_padded = pad_sequence([torch.tensor(seq_FGM) for seq_FGM in FGMs],\n"
     ]
    }
   ],
   "source": [
    "# noiseAmpRatioList = [1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
    "noiseAmpRatioList = [1e-1]\n",
    "\n",
    "correct = [0. for _ in noiseAmpRatioList]\n",
    "padLen = 5\n",
    "dSampRatio = 5\n",
    "for tsData in tsLoader:\n",
    "    tsInputData, tsLabel, tsFGM = tsData\n",
    "    tsInput = tsInputData[:, ::dSampRatio, :]\n",
    "    tsInput = tsInput * torch.numel(tsInput) / (LA.norm(tsInput) * nSubC * nRX)\n",
    "\n",
    "    # print(tsInput.shape, tsFGM.shape)\n",
    "    tsInputBatch = torch.empty((0, inputLenTime, nSubC*nRX)).to(device)\n",
    "    for i in range(0, tsInput.shape[1]-inputLenTime):\n",
    "        tsInputBatch = torch.cat((tsInputBatch, tsInput[:, i:i+inputLenTime, :]), 0)\n",
    "    tsSurroOutput = HARNetSurro(tsInputBatch)\n",
    "    # tsTargetInput = tsInput[:, padLen:, :] + tsSurroOutput\n",
    "    # for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "        # pred, label = getPredsGAIL(tsInput[:, padLen:, :], torch.unsqueeze(tsSurroOutput, 0), tsLabel,\\\n",
    "        #                             HARNetTarget, noiseAmpRatio)\n",
    "        \n",
    "        # correct[noiseAmpIndex] += (pred == label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TAR_BiLSTM_H_200_dS_10'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTMSurroModelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1664864/1903631498.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.features[idx], device=self.device).float()\n",
      "/tmp/ipykernel_1664864/1903631498.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  FGM = torch.tensor(self.FGM[idx], device=self.device).float()\n",
      "/tmp/ipykernel_1664864/1903631498.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], device=self.device).long()\n",
      "/home/byk004/24-RT_adv_HAR/utilities.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs],\n",
      "/home/byk004/24-RT_adv_HAR/utilities.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  FGM_padded = pad_sequence([torch.tensor(seq_FGM) for seq_FGM in FGMs],\n",
      "/tmp/ipykernel_1664864/3843910325.py:61: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  np.save(dataInput_fileName, np.array(inputList, dtype=object), allow_pickle=True)\n",
      "/tmp/ipykernel_1664864/3843910325.py:62: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  np.save(dataFGM_fileName, np.array(actsList, dtype=object), allow_pickle=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fall\n",
      "40\n",
      "run\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "batchSize = 1\n",
    "slideLen = 200\n",
    "seqLen = 1000\n",
    "padLen = 25\n",
    "noiseAmpRatio = 0.1\n",
    "dSampTarget = 2\n",
    "attackScheme = 'BC'\n",
    "\n",
    "for actInd, activity in enumerate(activities):\n",
    "    dataInput_fileName = \"/project/iarpa/wifiHAR/HAR_TAR/win_dSamp_\" +\\\n",
    "        str(dSampTarget)+ \"_\" + attackScheme + \"/input_\" + LSTMSurroModelName + \"_\" + activity\n",
    "    dataFGM_fileName = \"/project/iarpa/wifiHAR/HAR_TAR/win_dSamp_\" +\\\n",
    "        str(dSampTarget)+ \"_\" + attackScheme + \"/\" + attackScheme + \"_\" + LSTMSurroModelName + \"_\" + activity\n",
    "\n",
    "    print(activity)\n",
    "    inputList = []\n",
    "    actsList = []\n",
    "\n",
    "\n",
    "    tsDatasetAct = CSI_BCDataset(dataDict[activity], device, padLen=0)\n",
    "    tsDataset = list()\n",
    "    tsDataset.append(torch.utils.data.Subset(tsDatasetAct, tsDataList))\n",
    "    tsLoaderAct = DataLoader(torch.utils.data.ConcatDataset(tsDataset), batch_size=batchSize, shuffle=False, collate_fn=collate_fn_FGM)\n",
    "\n",
    "    # print(len(tsLoaderAct))\n",
    "    for tsData in tsLoaderAct:\n",
    "        tsInputData, tsLabel, tsFGM = tsData\n",
    "        tsDataWoPad = tsInputData[:, padLen:, :]\n",
    "        tsInput = tsInputData[:, ::dSampRatio, :]\n",
    "        tsInput = tsInput * torch.numel(tsInput) / (LA.norm(tsInput) * nSubC * nRX)\n",
    "\n",
    "        tsInputBatch = torch.empty((0, inputLenTime, nSubC*nRX)).to(device)\n",
    "        for i in range(0, tsInput.shape[1]-inputLenTime):\n",
    "            tsInputBatch = torch.cat((tsInputBatch, tsInput[:, i:i+inputLenTime, :]), 0)\n",
    "        tsSurroOutput = HARNetSurro(tsInputBatch)\n",
    "        # print(tsInputData.shape, tsInputBatch.shape, tsSurroOutput.shape)\n",
    "\n",
    "        actsDataUSamp = torch.Tensor().to(device)\n",
    "        for uSampIdx, tIdx in enumerate(range(0, tsDataWoPad.shape[1], dSampRatio)):\n",
    "            actsTimeSamp = tsSurroOutput[uSampIdx, :]\n",
    "            # print(actsTimeSamp.repeat(1, 5, 1).shape)\n",
    "            actsDataUSamp = torch.cat((actsDataUSamp, actsTimeSamp.repeat(1, 5, 1)), dim=1)\n",
    "        # print(actsDataUSamp.shape)\n",
    "\n",
    "        for tIdx in range(0, tsDataWoPad.shape[1], slideLen):\n",
    "            inputWin = tsDataWoPad[:, tIdx:tIdx+seqLen, :]\n",
    "            actsWin = actsDataUSamp[:, tIdx:tIdx+seqLen, :]\n",
    "            if inputWin.shape[1] < seqLen:\n",
    "                continue\n",
    "            # print(inputWin.shape, actsWin.shape)\n",
    "\n",
    "            noiseAmp = LA.norm(torch.flatten(inputWin)) * noiseAmpRatio\n",
    "            noiseFlatten = torch.flatten(actsWin)\n",
    "            noiseNormalized = torch.mul(torch.div(noiseFlatten,\\\n",
    "                LA.norm(noiseFlatten)), noiseAmp)\n",
    "            actsWin = noiseNormalized.view(inputWin.shape)\n",
    "\n",
    "            inputList.append(torch.squeeze(inputWin).cpu().detach())\n",
    "            actsList.append(torch.squeeze(actsWin).cpu().detach())\n",
    "\n",
    "    np.save(dataInput_fileName, np.array(inputList, dtype=object), allow_pickle=True)\n",
    "    np.save(dataFGM_fileName, np.array(actsList, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wifiHAR_vel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
