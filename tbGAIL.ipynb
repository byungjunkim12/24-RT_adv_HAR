{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "from GAIL.models.nets import Expert\n",
    "from GAIL.models.gail import GAIL\n",
    "\n",
    "from utilities import *\n",
    "from utilitiesDL import *\n",
    "\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity: fall trExpDataset: 93 trAgentDataset: 40 tsDataset: 311\n",
      "activity: pickup trExpDataset: 102 trAgentDataset: 44 tsDataset: 343\n",
      "activity: run trExpDataset: 253 trAgentDataset: 109 tsDataset: 847\n",
      "activity: sitdown trExpDataset: 86 trAgentDataset: 38 tsDataset: 290\n",
      "activity: standup trExpDataset: 63 trAgentDataset: 28 tsDataset: 213\n",
      "activity: walk trExpDataset: 308 trAgentDataset: 132 tsDataset: 1027\n"
     ]
    }
   ],
   "source": [
    "LSTMModelDir = './savedModels/selected/'\n",
    "\n",
    "inputJsonFileName = 'test'\n",
    "\n",
    "LSTMModelDir = './savedModels/selected/'\n",
    "inputJsonFile = open(\"./inputJson/GAIL/\" + inputJsonFileName + \".json\", \"r\")\n",
    "inputJson = json.load(inputJsonFile)\n",
    "LSTMModelName = inputJson['LSTMModelName']\n",
    "noiseAmpRatio = inputJson['noiseAmpRatio']\n",
    "trDataRatio = inputJson['trDataRatio']\n",
    "trExpDataRatio = inputJson['trExpDataRatio']\n",
    "nHiddenGAIL = inputJson['nHiddenGAIL']\n",
    "inputLenTime = inputJson['inputLenTime']\n",
    "GAILTrainConfig = inputJson['trainConfig']\n",
    "\n",
    "cudaID = 7\n",
    "padLen = 9\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "if cudaID >= 0:\n",
    "    device = torch.device(\"cuda:\"+str(cudaID))\n",
    "    cudaAvbl = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    cudaAvbl = False\n",
    "\n",
    "dataType = LSTMModelName.split('_')[0]\n",
    "if dataType == 'survey':\n",
    "    fs = 1000 # 1 kHz\n",
    "    nSubC = 30\n",
    "    nRX = 3\n",
    "    \n",
    "    winLen = 1000\n",
    "    thres = 60\n",
    "    slideLen = 400\n",
    "    activities = ['fall', 'pickup', 'run', 'sitdown', 'standup', 'walk']\n",
    "\n",
    "LSTMType = LSTMModelName.split('_')[1]\n",
    "bidirectional = (LSTMType == 'BLSTM')\n",
    "nHidden = int(LSTMModelName.split('_')[3])\n",
    "threshold = int(LSTMModelName.split('_')[5])\n",
    "nLayer = int(LSTMModelName.split('_')[7])\n",
    "\n",
    "saveFileName = LSTMModelName + '_' + inputJsonFileName\n",
    "\n",
    "# Load the LSTM model\n",
    "HARNet = LSTMNet(nClasses=len(activities), input_size=nSubC*nRX, bidirectional=bidirectional,\\\n",
    "                hidden_size=nHidden, num_layers=1, seq_length=winLen//2, device=device)\n",
    "HARNet.load_state_dict(torch.load(LSTMModelDir + LSTMModelName + '.cpkt'))\n",
    "# HARNet.to(device)\n",
    "\n",
    "# Load dataset labelled with FGM attack\n",
    "FGMdatasetDir = '/project/iarpa/wifiHAR/HAR_' + dataType + '/window_FGM_pad_' + str(padLen) + '/'\n",
    "dataDict = {file:[] for file in activities}\n",
    "# tsDataDict = {file:[] for file in activities}\n",
    "\n",
    "trExpDataset = list()\n",
    "trAgentDataset = list()\n",
    "# trDataset = list()\n",
    "tsDataset = list()\n",
    "correct = 0.0\n",
    "nData = 0.0\n",
    "for actInd, activity in enumerate(activities):\n",
    "    dataDict[activity] = defaultdict(list)\n",
    "\n",
    "    dataInputActFileName = FGMdatasetDir + 'input_' + LSTMModelName + '_' + activity + '.npy'\n",
    "    dataAct = np.load(dataInputActFileName)\n",
    "    dataDict[activity]['obs'] =\\\n",
    "        torch.reshape(torch.squeeze(torch.tensor(dataAct).to(device)), (-1, (winLen//2+padLen), nSubC*nRX))\n",
    "    \n",
    "    dataNoiseActFileName = FGMdatasetDir + 'noise_' + LSTMModelName + '_' + activity + '.npy'\n",
    "    dataNoise = np.load(dataNoiseActFileName)\n",
    "    dataDict[activity]['FGM'] = noiseAmpRatio *\\\n",
    "        torch.reshape(torch.squeeze(torch.tensor(dataNoise).to(device)), (-1, (winLen//2), nSubC*nRX))\n",
    "    \n",
    "    dataDict[activity]['label'] =\\\n",
    "        actInd * torch.ones_like(torch.empty(dataDict[activity]['obs'].shape[0], device=device), dtype=int) \n",
    "   \n",
    "    trObsBatchwoPad = dataDict[activity]['obs'][:, padLen:, :]\n",
    "    # print('obs:', trObsBatchwoPad.shape, 'FGM:',\\\n",
    "    #     dataDict[activity]['FGM'].shape, 'label:', dataDict[activity]['label'].shape)\n",
    "\n",
    "    pred_l,label_l = getPredsGAIL(trObsBatchwoPad, dataDict[activity]['FGM'], dataDict[activity]['label'],\\\n",
    "                                HARNet, noiseAmpRatio)\n",
    "    for pred, label in zip(pred_l, label_l):\n",
    "        nData += 1\n",
    "        correct += (pred == label)\n",
    "\n",
    "    datasetAct = FGMDataset(dataDict[activity], device)\n",
    "    trExpDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                                range(int(trDataRatio*trExpDataRatio*len(datasetAct)))))\n",
    "    trAgentDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                                  range(int(trDataRatio*trExpDataRatio*len(datasetAct)),\\\n",
    "                                                        int(trDataRatio*len(datasetAct)))))\n",
    "    tsDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                             range(int(trDataRatio*len(datasetAct)), len(datasetAct))))\n",
    "\n",
    "    print('activity:', activity, 'trExpDataset:', len(trExpDataset[-1]),\\\n",
    "          'trAgentDataset:', len(trAgentDataset[-1]), 'tsDataset:', len(tsDataset[-1]))\n",
    "\n",
    "trExpLoader = DataLoader(torch.utils.data.ConcatDataset(trExpDataset),\\\n",
    "                      batch_size=20, shuffle=True, generator=torch.Generator(device=device))\n",
    "trAgentLoader = DataLoader(torch.utils.data.ConcatDataset(trAgentDataset),\\\n",
    "                      batch_size=20, shuffle=True, generator=torch.Generator(device=device))\n",
    "tsLoader = DataLoader(torch.utils.data.ConcatDataset(tsDataset),\\\n",
    "                      batch_size=20, shuffle=True, generator=torch.Generator(device=device))\n",
    "\n",
    "\n",
    "# print('trExpLoader:', len(trExpLoader), 'trAgentLoader', len(trAgentLoader), 'tsLoader:', len(tsLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.nn import Module\n",
    "\n",
    "from GAIL.models.nets import PolicyNetwork, ValueNetwork, Discriminator\n",
    "from GAIL.utils.funcs import get_flat_grads, get_flat_params, set_params, \\\n",
    "    conjugate_gradient, rescale_and_linesearch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    from torch import FloatTensor\n",
    "\n",
    "\n",
    "class GAIL(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        nHidden,\n",
    "        padLen,\n",
    "        inputLenTime,\n",
    "        discrete,\n",
    "        device,\n",
    "        train_config=None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.nHidden = nHidden\n",
    "        self.padLen = padLen\n",
    "        self.inputLenTime = inputLenTime\n",
    "        self.discrete = discrete\n",
    "        self.device = device\n",
    "        self.train_config = train_config\n",
    "\n",
    "        self.pi = PolicyNetwork(self.state_dim, self.action_dim, self.nHidden, self.discrete, self.device)\n",
    "        self.v = ValueNetwork(self.state_dim, self.nHidden, self.device)\n",
    "        self.d = Discriminator(self.state_dim, self.action_dim, self.nHidden, self.discrete, self.device)\n",
    "\n",
    "    def get_networks(self):\n",
    "        return [self.pi, self.v]\n",
    "\n",
    "    def act(self, state):\n",
    "        self.pi.eval()\n",
    "        state = FloatTensor(state)\n",
    "        action = self.pi(state).sample()\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def eval(self, trAgentLoader, pi):\n",
    "        self.pi.load_state_dict(pi.state_dict())\n",
    "        self.pi.eval()\n",
    "        \n",
    "        nDataTrAgent = 0\n",
    "        for trAgentBatch in trAgentLoader:\n",
    "            nDataTrAgent += trAgentBatch['obs'].shape[0]\n",
    "\n",
    "        noiseAmpRatioList = [1e-5, 1e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 7.5e-2, 0.1, 0.2, 0.5]\n",
    "        correct = [0. for _ in noiseAmpRatioList]\n",
    "        lineBreakCount = 0\n",
    "        for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "            for trAgentBatch in trAgentLoader:\n",
    "                seqLength = trAgentBatch['obs'].shape[1] - self.padLen\n",
    "                obsBatch = torch.Tensor().to(device)\n",
    "                for inputLenIndex in range(self.inputLenTime):\n",
    "                    obsBatch = torch.cat((obsBatch,\\\n",
    "                        trAgentBatch['obs'][:, (padLen-self.inputLenTime+inputLenIndex+1):\\\n",
    "                                            (padLen-self.inputLenTime+inputLenIndex+1+seqLength),:]), dim=2)\n",
    "                    \n",
    "                obsBatchFlatten = obsBatch.transpose(0, 1).reshape(-1, obsBatch.shape[2])\n",
    "                actBatchFlatten = self.act(obsBatchFlatten)\n",
    "                actBatch = torch.reshape(actBatchFlatten, ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)\n",
    "                # actTorch = torch.reshape(torch.from_numpy(act), ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)                \n",
    "                obsLastBatch = obsBatch[:, :, -trAgentBatch['obs'].shape[2]:]\n",
    "                pred_l,label_l = getPredsGAIL(obsLastBatch,\\\n",
    "                                                actBatch, trAgentBatch['label'], HARNet, noiseAmpRatio)\n",
    "                for pred, label in zip(pred_l, label_l):\n",
    "                    correct[noiseAmpIndex] += (pred == label)\n",
    "\n",
    "            print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct[noiseAmpIndex]/nDataTrAgent), end=' ')\n",
    "            lineBreakCount += 1\n",
    "            if lineBreakCount == 5:\n",
    "                print('')\n",
    "                lineBreakCount = 0\n",
    "        if lineBreakCount != 0:\n",
    "            print('')\n",
    "\n",
    "\n",
    "    def train(self, HARNet, trExpLoader, trAgentLoader, tsLoader, render=False):\n",
    "        num_iters = self.train_config[\"num_iters\"]\n",
    "        lambda_ = self.train_config[\"lambda\"]\n",
    "        gae_gamma = self.train_config[\"gae_gamma\"]\n",
    "        gae_lambda = self.train_config[\"gae_lambda\"]\n",
    "        eps = self.train_config[\"epsilon\"]\n",
    "        max_kl = self.train_config[\"max_kl\"]\n",
    "        cg_damping = self.train_config[\"cg_damping\"]\n",
    "        opt_d_LR = self.train_config[\"opt_d_LR\"]\n",
    "        normalize_advantage = self.train_config[\"normalize_advantage\"]\n",
    "\n",
    "        opt_d = torch.optim.Adam(self.d.parameters(), lr=opt_d_LR)\n",
    "\n",
    "        noiseAmpRatioList = [1e-4, 1e-3, 1e-2, 0.1, 0.2]\n",
    "        # noiseAmpRatioList = [10]\n",
    "        print('----White-box attack performance (Expert)----')\n",
    "        print('[ampRatio, Acc.]:', end=' ')\n",
    "        nDataTrExp = 0\n",
    "        for trExpBatch in trExpLoader:\n",
    "            nDataTrExp += trExpBatch['obs'].shape[0]\n",
    "        nDataTrAgent = 0\n",
    "        for trAgentBatch in trAgentLoader:\n",
    "            nDataTrAgent += trAgentBatch['obs'].shape[0]\n",
    "        nDataTs = 0\n",
    "        for tsBatch in tsLoader:\n",
    "            nDataTs += tsBatch['obs'].shape[0]\n",
    "\n",
    "        lineBreakCount = 0\n",
    "        for noiseAmpRatio in noiseAmpRatioList:\n",
    "            correct = 0.\n",
    "            for trAgentBatch in trAgentLoader:\n",
    "                seqLength = trAgentBatch['obs'].shape[1] - self.padLen\n",
    "                trObsBatchwoPad = trAgentBatch['obs'][:, padLen:, :]\n",
    "                pred_l,label_l = getPredsGAIL(trObsBatchwoPad, trAgentBatch['FGM'], trAgentBatch['label'],\\\n",
    "                                              HARNet, noiseAmpRatio)\n",
    "                for pred, label in zip(pred_l, label_l):\n",
    "                    correct += (pred == label)\n",
    "            print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nDataTrAgent), end=' ')\n",
    "\n",
    "            lineBreakCount += 1\n",
    "            if lineBreakCount == 5:\n",
    "                print('')\n",
    "                lineBreakCount = 0\n",
    "        if lineBreakCount != 0:\n",
    "            print('')\n",
    "\n",
    "        print('----Random noise attack performance----')\n",
    "        print('[ampRatio, Acc.]:', end=' ')\n",
    "        for noiseAmpRatio in noiseAmpRatioList:\n",
    "            correct = 0.\n",
    "            lineBreakCount = 0\n",
    "            for trAgentBatch in trAgentLoader:\n",
    "                trObsBatchwoPad = trAgentBatch['obs'][:, padLen:, :]\n",
    "                noiseBatch = torch.randn(trObsBatchwoPad.shape).to(device)\n",
    "                pred_l,label_l = getPredsGAIL(trObsBatchwoPad, noiseBatch, trAgentBatch['label'],\\\n",
    "                                              HARNet, noiseAmpRatio)\n",
    "                for pred, label in zip(pred_l, label_l):\n",
    "                    correct += (pred == label)\n",
    "                # accuracyList.append(correct/nData)\n",
    "            print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nDataTrAgent), end=' ')\n",
    "            lineBreakCount += 1\n",
    "            if lineBreakCount == 5:\n",
    "                print('')\n",
    "                lineBreakCount = 0\n",
    "        if lineBreakCount != 0:\n",
    "            print('')\n",
    "\n",
    "        print('nDataTrExp:', nDataTrExp, 'nDataTrAgent:', nDataTrAgent, 'nDataTs:', int(nDataTs))\n",
    "        bestAcc = 1.0\n",
    "        accHistory = np.zeros((num_iters, len(noiseAmpRatioList)))\n",
    "        for i in range(num_iters):\n",
    "            if lineBreakCount != 0 and i!= 0:\n",
    "                print('')\n",
    "            print('Iter {}'.format(i), end=' ')\n",
    "            \n",
    "            obs = []\n",
    "            acts = []\n",
    "            rets = []\n",
    "            advs = []\n",
    "            gms = []\n",
    "\n",
    "            # nData = 0\n",
    "            correct = [0. for _ in noiseAmpRatioList]\n",
    "            for _, trAgentBatch in enumerate(trAgentLoader):\n",
    "                # obsAmp = LA.norm(trAgentBatch['obs'].view(trAgentBatch['obs'].shape[0], -1), dim=1)\n",
    "                obsBatch = torch.Tensor().to(device)\n",
    "                for inputLenIndex in range(self.inputLenTime):\n",
    "                    obsBatch = torch.cat((obsBatch,\\\n",
    "                        trAgentBatch['obs'][:, (padLen-self.inputLenTime+inputLenIndex+1):\\\n",
    "                                            (padLen-self.inputLenTime+inputLenIndex+1+seqLength),:]), dim=2)\n",
    "\n",
    "                obsBatchFlatten = obsBatch.transpose(0, 1).reshape(-1, obsBatch.shape[2])\n",
    "                actBatchFlatten = self.act(obsBatchFlatten)\n",
    "                actBatch = torch.reshape(actBatchFlatten, ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)\n",
    "                # actTorch = torch.reshape(torch.from_numpy(act), ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)                \n",
    "                obsLastBatch = obsBatch[:, :, -trAgentBatch['obs'].shape[2]:]\n",
    "                for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "                    pred_l,label_l = getPredsGAIL(obsLastBatch,\\\n",
    "                                                  actBatch, trAgentBatch['label'], HARNet, noiseAmpRatio)\n",
    "                    for pred, label in zip(pred_l, label_l):\n",
    "                        correct[noiseAmpIndex] += (pred == label)\n",
    "                    \n",
    "                obs.append(obsBatchFlatten)\n",
    "                acts.append(actBatchFlatten)\n",
    "\n",
    "                retsBatch = torch.Tensor().to(device)\n",
    "                advsBatch = torch.Tensor().to(device)\n",
    "                gmsBatch = torch.Tensor().to(device)\n",
    "                for _, trAgentData in enumerate(obsBatch):\n",
    "                    ep_obs = trAgentData\n",
    "                    ep_acts = torch.squeeze(actBatch[i, :, :])\n",
    "                    ep_gms = torch.pow(gae_gamma, torch.arange(seqLength)).to(device)\n",
    "                    ep_lmbs = torch.pow(gae_lambda, torch.arange(seqLength)).to(device)\n",
    "\n",
    "                    ep_costs = (-1) * torch.log(self.d(ep_obs, ep_acts)).squeeze().detach()\n",
    "                    ep_disc_costs = ep_gms * ep_costs\n",
    "                    ep_disc_rets = torch.flip(torch.flip(\\\n",
    "                        ep_disc_costs.to(device), dims=[0]).cumsum(dim=0), dims=[0])\n",
    "                    # ep_disc_rets = FloatTensor([sum(ep_disc_costs[i:]) for i in range(seqLength)]).to(device)\n",
    "                    ep_rets = ep_disc_rets / ep_gms\n",
    "                    retsBatch = torch.cat((retsBatch, ep_rets), dim=0)\n",
    "\n",
    "                    self.v.eval()\n",
    "                    curr_vals = self.v(ep_obs).detach()\n",
    "                    next_vals = torch.cat(\n",
    "                        (self.v(ep_obs)[1:], FloatTensor([[0.]]).to(device))).detach()\n",
    "                    ep_deltas = ep_costs.unsqueeze(-1) + gae_gamma * next_vals - curr_vals\n",
    "                    ep_advs = FloatTensor([\n",
    "                        ((ep_gms * ep_lmbs)[:seqLength - j].unsqueeze(-1) * ep_deltas[j:]).sum()\n",
    "                        for j in range(seqLength)]).to(device)\n",
    "\n",
    "                    advsBatch = torch.cat((advsBatch, ep_advs))\n",
    "                    gmsBatch = torch.cat((gmsBatch, ep_gms))\n",
    "                \n",
    "                rets.append(retsBatch)\n",
    "                advs.append(advsBatch)\n",
    "                gms.append(gmsBatch)\n",
    "            \n",
    "            # print('rets:', len(rets), 'advs:', len(advs), 'gms:', len(gms))\n",
    "            if normalize_advantage:\n",
    "                advsFlatten = torch.cat(advs)\n",
    "                advsFlatten = (advsFlatten - advsFlatten.mean()) / (advsFlatten.std() + 1e-8)\n",
    "                advs = torch.split(advsFlatten, [len(advsBatch) for advsBatch in advs])\n",
    "                \n",
    "            self.d.train()\n",
    "            expScores = torch.Tensor().to(device)\n",
    "            for trExpBatch in trExpLoader:\n",
    "                # seqLength = trExpBatch['obs'].shape[1] - self.padLen\n",
    "                # expObsBatch = trExpBatch['obs'][:, padLen:, :]\n",
    "                # obsAmp = LA.norm(trAgentBatch['obs'].view(trAgentBatch['obs'].shape[0], -1), dim=1)\n",
    "                expObsBatch = torch.Tensor().to(device)\n",
    "                for inputLenIndex in range(self.inputLenTime):\n",
    "                    expObsBatch = torch.cat((expObsBatch,\\\n",
    "                        trExpBatch['obs'][:, (padLen-self.inputLenTime+inputLenIndex+1):\\\n",
    "                                            (padLen-self.inputLenTime+inputLenIndex+1+seqLength),:]), dim=2)\n",
    "\n",
    "                expObsBatch = expObsBatch.transpose(0, 1).reshape(-1, expObsBatch.shape[2])\n",
    "                expActBatch = trExpBatch['FGM'].transpose(0, 1).reshape(-1, trExpBatch['FGM'].shape[2])\n",
    "                # expScores = self.d.get_logits(expObsBatch, expActBatch)\n",
    "                # print(expObsBatch.shape, expActBatch.shape)\n",
    "                expScores = torch.cat((expScores, self.d.get_logits(expObsBatch, expActBatch)), dim=0)\n",
    "            \n",
    "            agentScores = torch.Tensor().to(device)\n",
    "            for agentObsBatch, agentActsBatch in zip(obs, acts):\n",
    "                agentScores = torch.cat((agentScores, self.d.get_logits(agentObsBatch, agentActsBatch)), dim=0)\n",
    "            # print(expScores.shape, agentScores.shape)\n",
    "\n",
    "\n",
    "            opt_d.zero_grad()\n",
    "            lossExp = torch.nn.functional.binary_cross_entropy_with_logits(\\\n",
    "                expScores, torch.zeros_like(expScores))\n",
    "            lossAgent = torch.nn.functional.binary_cross_entropy_with_logits(\\\n",
    "                agentScores, torch.ones_like(agentScores))\n",
    "            loss = lossExp + lossAgent\n",
    "            loss.backward()\n",
    "            opt_d.step()\n",
    "\n",
    "            # print('scores: {0:.3f}, {1:.3f}'.format\\\n",
    "            #       (torch.mean(expScores).item(), torch.mean(agentScores).item()), end=' ')\n",
    "            print('scores: {0:.3f}, {1:.3f}'.format\\\n",
    "                  (torch.mean(expScores).item(), torch.mean(agentScores).item()))\n",
    "\n",
    "            del expScores\n",
    "            del agentScores\n",
    "\n",
    "            self.v.train()\n",
    "            for obsBatch, actsBatch, retsBatch in zip(obs, acts, rets):\n",
    "                # print(obsBatch.shape, retsBatch.shape, advsBatch.shape, gmsBatch.shape)\n",
    "                old_params = get_flat_params(self.v).detach()\n",
    "                old_vBatch = self.v(obsBatch).detach()\n",
    "            \n",
    "                def constraint():\n",
    "                    return ((old_vBatch - self.v(obsBatch)) ** 2).mean()\n",
    "            \n",
    "                grad_diff = get_flat_grads(constraint(), self.v)\n",
    "\n",
    "                def Hv(v):\n",
    "                    hessian = get_flat_grads(torch.dot(grad_diff, v), self.v).detach()\n",
    "                    return hessian\n",
    "\n",
    "                g = get_flat_grads(\\\n",
    "                    (-1*(self.v(obsBatch).squeeze() - retsBatch) ** 2).mean(), self.v).detach()\n",
    "                s = conjugate_gradient(Hv, g).detach()\n",
    "                Hs = Hv(s).detach()\n",
    "                alpha = torch.sqrt(2 * eps / (torch.dot(s, Hs) + 1e-8)).detach()\n",
    "                new_params = old_params + alpha * s\n",
    "                # print('v:', old_params.norm().item(), alpha.item(), s.norm().item())\n",
    "                set_params(self.v, new_params)\n",
    "                # print('v:', self.v.net[0].weight[1, :2].squeeze())\n",
    "\n",
    "            # print('iter final v:', self.v.net[0].weight[1, :5].squeeze().detach().cpu().numpy())\n",
    "            \n",
    "            self.pi.train()\n",
    "            for obsBatch, actsBatch, advsBatch, gmsBatch in zip(obs, acts, advs, gms):\n",
    "                old_params = get_flat_params(self.pi).detach()\n",
    "                old_distb = self.pi(obsBatch)\n",
    "\n",
    "                def L():\n",
    "                    distb = self.pi(obsBatch)\n",
    "                    return (advsBatch * torch.exp(distb.log_prob(actsBatch)\\\n",
    "                                    - old_distb.log_prob(actsBatch).detach())).mean()\n",
    "                    # return torch.distributions.kl.kl_divergence(distb, old_distb).mean()\n",
    "\n",
    "                def kld():\n",
    "                    distb = self.pi(obsBatch)\n",
    "                    old_mean = old_distb.mean.detach()\n",
    "                    old_cov = old_distb.covariance_matrix.sum(-1).detach()\n",
    "                    mean = distb.mean\n",
    "                    cov = distb.covariance_matrix.sum(-1)\n",
    "                    return (0.5) * ((old_cov / cov).sum(-1)\\\n",
    "                            + (((old_mean - mean) ** 2) / cov).sum(-1)\n",
    "                            - self.action_dim\n",
    "                            + torch.log(cov).sum(-1)\n",
    "                            - torch.log(old_cov).sum(-1)).mean()\n",
    "\n",
    "                grad_kld_old_param = get_flat_grads(kld(), self.pi)\n",
    "\n",
    "                def Hv(v):\n",
    "                    hessian = get_flat_grads(torch.dot(grad_kld_old_param, v), self.pi).detach()\n",
    "                    return hessian + cg_damping * v\n",
    "                \n",
    "                g = get_flat_grads(L(), self.pi).detach()\n",
    "                s = conjugate_gradient(Hv, g).detach()\n",
    "                Hs = Hv(s).detach()\n",
    "                new_params = rescale_and_linesearch(g, s, Hs, max_kl, L, kld, old_params, self.pi)\n",
    "\n",
    "                disc_causal_entropy = ((-1) * gmsBatch * self.pi(obsBatch).log_prob(actsBatch)).mean()\n",
    "                grad_disc_causal_entropy = get_flat_grads(disc_causal_entropy, self.pi)\n",
    "                new_params += lambda_ * grad_disc_causal_entropy\n",
    "                # print('pi:', new_params.norm().item(), lambda_, grad_disc_causal_entropy.norm().item())\n",
    "\n",
    "                set_params(self.pi, new_params)\n",
    "                # print('pi:', self.pi.net[0].weight[1, :2].squeeze())\n",
    "                # break\n",
    "            \n",
    "            # print('iter final pi:', self.pi.net[0].weight[1, :5].squeeze().detach().cpu().numpy())\n",
    "\n",
    "            print('[ampRatio, Acc.]:', end=' ')\n",
    "            lineBreakCount = 0\n",
    "            ampSaveCriterion = 0.1\n",
    "            for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "                print('[{0}, {1:.3f}]'.\\\n",
    "                        format(noiseAmpRatio, correct[noiseAmpIndex]/nDataTrAgent), end=' ')\n",
    "                accHistory[i, noiseAmpIndex] = correct[noiseAmpIndex]/nDataTrAgent\n",
    "\n",
    "                lineBreakCount += 1\n",
    "                if lineBreakCount == 5:\n",
    "                    print('')\n",
    "                    lineBreakCount = 0\n",
    "\n",
    "            with open('./savedModels/GAIL/logs/' + saveFileName + '_accHistory.npy', 'wb') as f:\n",
    "                print(i, end=' ')\n",
    "                print(accHistory[i, :])\n",
    "                np.save(f, accHistory)\n",
    "\n",
    "            compAmpRatio = np.where(np.array(noiseAmpRatioList) == ampSaveCriterion)[0][0]\n",
    "            if correct[compAmpRatio]/nDataTrAgent < bestAcc:\n",
    "                bestAcc = correct[compAmpRatio]/nDataTrAgent\n",
    "                torch.save(self.pi.state_dict(), './savedModels/GAIL/' + saveFileName + '_pi.cpkt')\n",
    "                torch.save(self.v.state_dict(), './savedModels/GAIL/' + saveFileName + '_v.cpkt')\n",
    "                torch.save(self.d.state_dict(), './savedModels/GAIL/' + saveFileName + '_d.cpkt')\n",
    "                print('model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "----White-box attack performance (Expert)----\n",
      "[ampRatio, Acc.]: [0.0001, 0.972] [0.001, 0.964] [0.01, 0.565] [0.1, 0.153] [0.2, 0.123] \n",
      "----Random noise attack performance----\n",
      "[ampRatio, Acc.]: [0.0001, 0.974] [0.001, 0.974] [0.01, 0.974] [0.1, 0.803] [0.2, 0.478] \n",
      "nDataTrExp: 905 nDataTrAgent: 391 nDataTs: 3031\n",
      "Iter 0 scores: -0.030, -0.037\n",
      "[ampRatio, Acc.]: [0.0001, 0.974] [0.001, 0.974] [0.01, 0.974] [0.1, 0.788] [0.2, 0.504] \n",
      "0 [0.97442455 0.97442455 0.97442455 0.78772379 0.50383632]\n",
      "model saved!\n",
      "Iter 1 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m GAIL(state_dim\u001b[38;5;241m=\u001b[39mnSubC\u001b[38;5;241m*\u001b[39mnRX\u001b[38;5;241m*\u001b[39minputLenTime, action_dim\u001b[38;5;241m=\u001b[39mnSubC\u001b[38;5;241m*\u001b[39mnRX, nHidden\u001b[38;5;241m=\u001b[39mnHiddenGAIL,\\\n\u001b[1;32m      4\u001b[0m             padLen\u001b[38;5;241m=\u001b[39mpadLen, inputLenTime\u001b[38;5;241m=\u001b[39minputLenTime, discrete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice,\\\n\u001b[1;32m      5\u001b[0m             train_config\u001b[38;5;241m=\u001b[39mGAILTrainConfig)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(trExpLoader.device)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHARNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrExpLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrAgentLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtsLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[60], line 220\u001b[0m, in \u001b[0;36mGAIL.train\u001b[0;34m(self, HARNet, trExpLoader, trAgentLoader, tsLoader, render)\u001b[0m\n\u001b[1;32m    217\u001b[0m next_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    218\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv(ep_obs)[\u001b[38;5;241m1\u001b[39m:], FloatTensor([[\u001b[38;5;241m0.\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device)))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    219\u001b[0m ep_deltas \u001b[38;5;241m=\u001b[39m ep_costs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m gae_gamma \u001b[38;5;241m*\u001b[39m next_vals \u001b[38;5;241m-\u001b[39m curr_vals\n\u001b[0;32m--> 220\u001b[0m ep_advs \u001b[38;5;241m=\u001b[39m FloatTensor([\n\u001b[1;32m    221\u001b[0m     ((ep_gms \u001b[38;5;241m*\u001b[39m ep_lmbs)[:seqLength \u001b[38;5;241m-\u001b[39m j]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m ep_deltas[j:])\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seqLength)])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    224\u001b[0m advsBatch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((advsBatch, ep_advs))\n\u001b[1;32m    225\u001b[0m gmsBatch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((gmsBatch, ep_gms))\n",
      "Cell \u001b[0;32mIn[60], line 221\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    217\u001b[0m next_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    218\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv(ep_obs)[\u001b[38;5;241m1\u001b[39m:], FloatTensor([[\u001b[38;5;241m0.\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device)))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    219\u001b[0m ep_deltas \u001b[38;5;241m=\u001b[39m ep_costs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m gae_gamma \u001b[38;5;241m*\u001b[39m next_vals \u001b[38;5;241m-\u001b[39m curr_vals\n\u001b[1;32m    220\u001b[0m ep_advs \u001b[38;5;241m=\u001b[39m FloatTensor([\n\u001b[0;32m--> 221\u001b[0m     (\u001b[43m(\u001b[49m\u001b[43mep_gms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mep_lmbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mseqLength\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m ep_deltas[j:])\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seqLength)])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    224\u001b[0m advsBatch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((advsBatch, ep_advs))\n\u001b[1;32m    225\u001b[0m gmsBatch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((gmsBatch, ep_gms))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputLenTime = 3\n",
    "print(inputLenTime)\n",
    "model = GAIL(state_dim=nSubC*nRX*inputLenTime, action_dim=nSubC*nRX, nHidden=nHiddenGAIL,\\\n",
    "            padLen=padLen, inputLenTime=inputLenTime, discrete=False, device=device,\\\n",
    "            train_config=GAILTrainConfig)\n",
    "# print(trExpLoader.device)\n",
    "model.train(HARNet, trExpLoader, trAgentLoader, tsLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-05, 0.974] [0.0001, 0.974] [0.0005, 0.974] [0.001, 0.974] [0.002, 0.974] \n",
      "[0.005, 0.974] [0.01, 0.974] [0.02, 0.974] [0.05, 0.962] [0.075, 0.900] \n",
      "[0.1, 0.785] [0.2, 0.483] [0.5, 0.297] \n"
     ]
    }
   ],
   "source": [
    "# HARNet = LSTMNet(nClasses=len(activities), input_size=nSubC*nRX, bidirectional=bidirectional,\\\n",
    "#                  hidden_size=nHidden, num_layers=nLayer, seq_length=winLen//2, device=device)\n",
    "\n",
    "inputLenTime = 10\n",
    "nHiddenGAIL = 100\n",
    "LRstr = '5e-5'\n",
    "pi = PolicyNetwork(nSubC*nRX*inputLenTime, nSubC*nRX, nHiddenGAIL, False, device)\n",
    "# v = ValueNetwork(nSubC*nRX, device)\n",
    "# d = Discriminator(nSubC*nRX, nSubC*nRX, False, device)\n",
    "\n",
    "# GAILConfigName = 'GAILConfig01_LRe-3'\n",
    "GAILConfigName = 'GAILJson_TL_' + str(inputLenTime) + '_' + str(nHiddenGAIL) + '_LR' + LRstr\n",
    "\n",
    "\n",
    "pi.load_state_dict(torch.load('./savedModels/GAIL/' + LSTMModelName + '_' + GAILConfigName + '_pi.cpkt'))\n",
    "\n",
    "GAILEvalModel = GAIL(state_dim=nSubC*nRX*inputLenTime, action_dim=nSubC*nRX, nHidden=nHiddenGAIL,\\\n",
    "            padLen=padLen, inputLenTime=inputLenTime, discrete=False,\\\n",
    "            device=device, train_config=GAILTrainConfig)\n",
    "\n",
    "GAILEvalModel.eval(trAgentLoader, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDataTrAgent = 0\n",
    "for trAgentBatch in trAgentLoader:\n",
    "    nDataTrAgent += trAgentBatch['obs'].shape[0]\n",
    "noiseAmpRatioList = [1e-5, 1e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 7.5e-2, 0.1, 0.2, 0.5]\n",
    "\n",
    "lineBreakCount = 0\n",
    "for noiseAmpRatio in noiseAmpRatioList:\n",
    "    correct = 0.\n",
    "    \n",
    "    for trAgentBatch in trAgentLoader:\n",
    "        pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], trAgentBatch['FGM'], trAgentBatch['label'],\\\n",
    "                                        HARNet, noiseAmpRatio)\n",
    "        for pred, label in zip(pred_l, label_l):\n",
    "            correct += (pred == label)\n",
    "    print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nDataTrAgent), end=' ')\n",
    "    lineBreakCount += 1\n",
    "    if lineBreakCount == 4:\n",
    "        print('')\n",
    "        lineBreakCount = 0\n",
    "\n",
    "if lineBreakCount != 0:\n",
    "    print('')\n",
    "lineBreakCount = 0\n",
    "for noiseAmpRatio in noiseAmpRatioList:\n",
    "    correct = 0.\n",
    "    for trAgentBatch in trAgentLoader:\n",
    "        noiseBatch = torch.randn(trAgentBatch['obs'].shape).to(device)\n",
    "        pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], noiseBatch, trAgentBatch['label'],\\\n",
    "                                        HARNet, noiseAmpRatio)\n",
    "        for pred, label in zip(pred_l, label_l):\n",
    "            correct += (pred == label)\n",
    "        # accuracyList.append(correct/nData)\n",
    "    print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nDataTrAgent), end=' ')\n",
    "    lineBreakCount += 1\n",
    "    if lineBreakCount == 4:\n",
    "        print('')\n",
    "        lineBreakCount = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAILJson_TL_10_100_LR5e-5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8056266 , 0.81841432, 0.80306905, 0.81841432, 0.81841432,\n",
       "       0.81585678, 0.79028133, 0.78772379, 0.83120205, 0.80818414,\n",
       "       0.79795396, 0.82352941, 0.83631714, 0.81841432, 0.82097187,\n",
       "       0.81074169, 0.82352941, 0.83631714, 0.83631714, 0.84398977,\n",
       "       0.85677749, 0.8516624 , 0.8516624 , 0.84910486, 0.8286445 ,\n",
       "       0.84143223, 0.83375959, 0.83120205, 0.83631714, 0.82352941,\n",
       "       0.83120205, 0.8286445 , 0.84143223, 0.8286445 , 0.81841432,\n",
       "       0.81329923, 0.81329923, 0.82608696, 0.81841432, 0.84143223,\n",
       "       0.83120205, 0.8286445 , 0.82097187, 0.81329923, 0.81585678,\n",
       "       0.80818414, 0.81329923, 0.84143223, 0.83887468, 0.86700767,\n",
       "       0.85677749, 0.84143223, 0.83120205, 0.83375959, 0.8516624 ,\n",
       "       0.84910486, 0.80818414, 0.82097187, 0.82097187, 0.81841432,\n",
       "       0.80818414, 0.82097187, 0.82097187, 0.8286445 , 0.79283887,\n",
       "       0.81074169, 0.80818414, 0.7826087 , 0.79795396, 0.79028133,\n",
       "       0.8056266 , 0.8056266 , 0.82097187, 0.84654731, 0.84398977,\n",
       "       0.83631714, 0.83375959, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputLenTime = 10\n",
    "nHiddenGAIL = 100\n",
    "LRstr = '5e-5'\n",
    "GAILConfigName = 'GAILJson_TL_' + str(inputLenTime) + '_' + str(nHiddenGAIL) + '_LR' + LRstr\n",
    "\n",
    "accHistory = np.load('./savedModels/GAIL/logs/' + LSTMModelName + '_' + GAILConfigName + '_accHistory.npy')\n",
    "print(GAILConfigName)\n",
    "# with open('./savedModels/GAIL/logs/' + LSTMModelName + '_test_accHistory.npy', 'rb') as f:\n",
    "#     accHistory = np.load(f)\n",
    "# accHistory = np.load('./savedModels/GAIL/logs/' + LSTMModelName + '_test_accHistory.npy')\n",
    "\n",
    "accHistory[:100, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wifiHAR_vel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
