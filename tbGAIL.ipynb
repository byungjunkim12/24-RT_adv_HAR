{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "from GAIL.models.nets import Expert\n",
    "from GAIL.models.gail import GAIL\n",
    "\n",
    "from utilities import *\n",
    "from utilitiesDL import *\n",
    "\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity: fall trExpDataset: 93 trAgentDataset: 39 tsDataset: 311\n",
      "activity: pickup trExpDataset: 103 trAgentDataset: 45 tsDataset: 347\n",
      "activity: run trExpDataset: 253 trAgentDataset: 109 tsDataset: 847\n",
      "activity: sitdown trExpDataset: 86 trAgentDataset: 37 tsDataset: 289\n",
      "activity: standup trExpDataset: 64 trAgentDataset: 27 tsDataset: 214\n",
      "activity: walk trExpDataset: 307 trAgentDataset: 132 tsDataset: 1026\n",
      "trExpLoader: 46 trAgentLoader 20 tsLoader: 152\n"
     ]
    }
   ],
   "source": [
    "DataFGMDir = '/project/iarpa/wifiHAR/HAR_survey/window_FGM/'\n",
    "LSTMModelDir = './savedModels/selected/'\n",
    "\n",
    "inputJsonFileName = 'test'\n",
    "\n",
    "LSTMModelDir = './savedModels/selected/'\n",
    "inputJsonFile = open(\"./inputJson/GAIL/\" + inputJsonFileName + \".json\", \"r\")\n",
    "inputJson = json.load(inputJsonFile)\n",
    "LSTMModelName = inputJson['LSTMModelName']\n",
    "noiseAmpRatio = inputJson['noiseAmpRatio']\n",
    "trDataRatio = inputJson['trDataRatio']\n",
    "trExpDataRatio = inputJson['trExpDataRatio']\n",
    "GAILTrainConfig = inputJson['trainConfig']\n",
    "\n",
    "cudaID = 5\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "if cudaID >= 0:\n",
    "    device = torch.device(\"cuda:\"+str(cudaID))\n",
    "    cudaAvbl = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    cudaAvbl = False\n",
    "\n",
    "dataType = LSTMModelName.split('_')[0]\n",
    "if dataType == 'survey':\n",
    "    fs = 1000 # 1 kHz\n",
    "    nSubC = 30\n",
    "    nRX = 3\n",
    "    \n",
    "    winLen = 1000\n",
    "    thres = 60\n",
    "    slideLen = 400\n",
    "    activities = ['fall', 'pickup', 'run', 'sitdown', 'standup', 'walk']\n",
    "\n",
    "LSTMType = LSTMModelName.split('_')[1]\n",
    "bidirectional = (LSTMType == 'BLSTM')\n",
    "nHidden = int(LSTMModelName.split('_')[3])\n",
    "threshold = int(LSTMModelName.split('_')[5])\n",
    "nLayer = int(LSTMModelName.split('_')[7])\n",
    "\n",
    "# Load the LSTM model\n",
    "HARNet = LSTMNet(nClasses=len(activities), input_size=nSubC*nRX, bidirectional=bidirectional,\\\n",
    "                hidden_size=nHidden, num_layers=1, seq_length=winLen//2, device=device)\n",
    "HARNet.load_state_dict(torch.load(LSTMModelDir + LSTMModelName + '.cpkt'))\n",
    "# HARNet.to(device)\n",
    "\n",
    "# Load dataset labelled with FGM attack\n",
    "FGMdatasetDir = '/project/iarpa/wifiHAR/HAR_' + dataType + '/window_FGM/'\n",
    "dataDict = {file:[] for file in activities}\n",
    "tsDataDict = {file:[] for file in activities}\n",
    "\n",
    "trExpDataset = list()\n",
    "trAgentDataset = list()\n",
    "# trDataset = list()\n",
    "tsDataset = list()\n",
    "for actInd, activity in enumerate(activities):\n",
    "    dataDict[activity] = defaultdict(list)\n",
    "\n",
    "    dataActFileName = FGMdatasetDir + LSTMModelName + '_' + activity + '.pt'\n",
    "    dataAct = torch.load(dataActFileName)\n",
    "\n",
    "    # dataDict[activity]['obs'] =\\\n",
    "    #     torch.reshape(torch.squeeze(dataAct[0, :, :]), (-1, winLen//2, nSubC*nRX)).detach().cpu().numpy()\n",
    "    # dataDict[activity]['FGM'] = noiseAmpRatio *\\\n",
    "    #     torch.reshape(torch.squeeze(torch.squeeze(dataAct[1, :, :])),\\\n",
    "    #                   (-1, winLen//2, nSubC*nRX)).detach().cpu().numpy()\n",
    "    # dataDict[activity]['label'] =\\\n",
    "    #     actInd * np.ones((dataDict[activity]['obs'].shape[0]), dtype=int)\n",
    "\n",
    "    dataDict[activity]['obs'] =\\\n",
    "        torch.reshape(torch.squeeze(dataAct[0, :, :]), (-1, winLen//2, nSubC*nRX)).to(device)\n",
    "    # print(dataAct[0, :, :].shape, dataDict[activity]['obs'].shape)\n",
    "    dataDict[activity]['FGM'] = noiseAmpRatio *\\\n",
    "        torch.reshape(torch.squeeze(torch.squeeze(dataAct[1, :, :])),\\\n",
    "                      (-1, winLen//2, nSubC*nRX)).to(device)\n",
    "    dataDict[activity]['label'] =\\\n",
    "        actInd * torch.ones_like(torch.empty(dataDict[activity]['obs'].shape[0], device=device), dtype=int).to(device)\n",
    "\n",
    "\n",
    "    datasetAct = FGMDataset(dataDict[activity], device)\n",
    "    trExpDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                                range(int(trDataRatio*trExpDataRatio*len(datasetAct)))))\n",
    "    trAgentDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                                  range(int(trDataRatio*trExpDataRatio*len(datasetAct)),\\\n",
    "                                                        int(trDataRatio*len(datasetAct)))))\n",
    "    tsDataset.append(torch.utils.data.Subset(datasetAct,\\\n",
    "                                             range(int(trDataRatio*len(datasetAct)), len(datasetAct))))\n",
    "\n",
    "    print('activity:', activity, 'trExpDataset:', len(trExpDataset[-1]),\\\n",
    "          'trAgentDataset:', len(trAgentDataset[-1]), 'tsDataset:', len(tsDataset[-1]))\n",
    "\n",
    "\n",
    "trExpLoader = DataLoader(torch.utils.data.ConcatDataset(trExpDataset),\\\n",
    "                      batch_size=20, shuffle=True, generator=torch.Generator(device=device))\n",
    "trAgentLoader = DataLoader(torch.utils.data.ConcatDataset(trAgentDataset),\\\n",
    "                      batch_size=20, shuffle=True, generator=torch.Generator(device=device))\n",
    "tsLoader = DataLoader(torch.utils.data.ConcatDataset(tsDataset),\\\n",
    "                      batch_size=20, shuffle=True, generator=torch.Generator(device=device))\n",
    "\n",
    "print('trExpLoader:', len(trExpLoader), 'trAgentLoader', len(trAgentLoader), 'tsLoader:', len(tsLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.nn import Module\n",
    "\n",
    "from GAIL.models.nets import PolicyNetwork, ValueNetwork, Discriminator\n",
    "from GAIL.utils.funcs import get_flat_grads, get_flat_params, set_params, \\\n",
    "    conjugate_gradient, rescale_and_linesearch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    from torch import FloatTensor\n",
    "\n",
    "\n",
    "class GAIL(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        discrete,\n",
    "        device,\n",
    "        train_config=None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.discrete = discrete\n",
    "        self.device = device\n",
    "        self.train_config = train_config\n",
    "\n",
    "        self.pi = PolicyNetwork(self.state_dim, self.action_dim, self.discrete, self.device)\n",
    "        self.v = ValueNetwork(self.state_dim, self.device)\n",
    "        self.d = Discriminator(self.state_dim, self.action_dim, self.discrete, self.device)\n",
    "\n",
    "    def get_networks(self):\n",
    "        return [self.pi, self.v]\n",
    "\n",
    "    def act(self, state):\n",
    "        self.pi.eval()\n",
    "        state = FloatTensor(state)\n",
    "        action = self.pi(state).sample()\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def eval(self, trAgentLoader, pi, v, d):\n",
    "        self.pi.load_state_dict(pi.state_dict())\n",
    "        self.v.load_state_dict(v.state_dict())\n",
    "        self.d.load_state_dict(d.state_dict())\n",
    "        \n",
    "        nDataTrAgent = 0\n",
    "        for trAgentBatch in trAgentLoader:\n",
    "            nDataTrAgent += trAgentBatch['obs'].shape[0]\n",
    "\n",
    "        noiseAmpRatioList = [1e-5, 1e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 7.5e-2, 0.1, 0.2, 0.5]\n",
    "        correct = [0. for _ in noiseAmpRatioList]\n",
    "        for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "            for trAgentBatch in trAgentLoader:\n",
    "                obsBatchFlatten = trAgentBatch['obs'].transpose(0, 1).reshape(-1, trAgentBatch['obs'].shape[2])\n",
    "                actBatchFlatten = self.act(obsBatchFlatten)\n",
    "                actBatch = torch.reshape(actBatchFlatten, ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)\n",
    "\n",
    "                pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], actBatch, trAgentBatch['label'],\\\n",
    "                                              HARNet, noiseAmpRatio)\n",
    "                for pred, label in zip(pred_l, label_l):\n",
    "                    correct[noiseAmpIndex] += (pred == label)\n",
    "            print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct[noiseAmpIndex]/nDataTrAgent), end=' ')\n",
    "\n",
    "    def train(self, HARNet, trExpLoader, trAgentLoader, tsLoader, render=False):\n",
    "        num_iters = self.train_config[\"num_iters\"]\n",
    "        lambda_ = self.train_config[\"lambda\"]\n",
    "        gae_gamma = self.train_config[\"gae_gamma\"]\n",
    "        gae_lambda = self.train_config[\"gae_lambda\"]\n",
    "        eps = self.train_config[\"epsilon\"]\n",
    "        max_kl = self.train_config[\"max_kl\"]\n",
    "        cg_damping = self.train_config[\"cg_damping\"]\n",
    "        opt_d_LR = self.train_config[\"opt_d_LR\"]\n",
    "        normalize_advantage = self.train_config[\"normalize_advantage\"]\n",
    "\n",
    "        opt_d = torch.optim.Adam(self.d.parameters(), lr=opt_d_LR)\n",
    "\n",
    "        noiseAmpRatioList = [1e-4, 1e-3, 1e-2, 0.1]\n",
    "        # noiseAmpRatioList = [10]\n",
    "        print('----White-box attack performance (Expert)----')\n",
    "        lineBreakCount = 0\n",
    "        print('[ampRatio, Acc.]:', end=' ')\n",
    "        nDataTrExp = 0\n",
    "        for trExpBatch in trExpLoader:\n",
    "            nDataTrExp += trExpBatch['obs'].shape[0]\n",
    "        nDataTrAgent = 0\n",
    "        for trAgentBatch in trAgentLoader:\n",
    "            nDataTrAgent += trAgentBatch['obs'].shape[0]\n",
    "        nDataTs = 0\n",
    "        for tsBatch in tsLoader:\n",
    "            nDataTs += tsBatch['obs'].shape[0]\n",
    "\n",
    "        for noiseAmpRatio in noiseAmpRatioList:\n",
    "            correct = 0.\n",
    "            for trAgentBatch in trAgentLoader:\n",
    "                pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], trAgentBatch['FGM'], trAgentBatch['label'],\\\n",
    "                                              HARNet, noiseAmpRatio)\n",
    "                for pred, label in zip(pred_l, label_l):\n",
    "                    correct += (pred == label)\n",
    "            print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nDataTrAgent), end=' ')\n",
    "\n",
    "            lineBreakCount += 1\n",
    "            if lineBreakCount == 4:\n",
    "                print('')\n",
    "                lineBreakCount = 0\n",
    "\n",
    "        if lineBreakCount != 0:\n",
    "            print('')\n",
    "        print('----Random noise attack performance----')\n",
    "        print('[ampRatio, Acc.]:', end=' ')\n",
    "        for noiseAmpRatio in noiseAmpRatioList:\n",
    "            correct = 0.\n",
    "            for trAgentBatch in trAgentLoader:\n",
    "                noiseBatch = torch.randn(trAgentBatch['obs'].shape).to(device)\n",
    "                pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], noiseBatch, trAgentBatch['label'],\\\n",
    "                                              HARNet, noiseAmpRatio)\n",
    "                for pred, label in zip(pred_l, label_l):\n",
    "                    correct += (pred == label)\n",
    "                # accuracyList.append(correct/nData)\n",
    "            print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nDataTrAgent), end=' ')\n",
    "            lineBreakCount += 1\n",
    "            if lineBreakCount == 4:\n",
    "                print('')\n",
    "                lineBreakCount = 0\n",
    "\n",
    "\n",
    "        if lineBreakCount != 0:\n",
    "            print('')\n",
    "\n",
    "        print('nDataTrExp:', nDataTrExp, 'nDataTrAgent:', nDataTrAgent, 'nDataTs:', int(nDataTs))\n",
    "        bestAcc = 1.0\n",
    "        for i in range(num_iters):\n",
    "            if lineBreakCount != 0 and i!= 0:\n",
    "                print('')\n",
    "            print('Iter {}'.format(i), end=' ')\n",
    "            \n",
    "            obs = []\n",
    "            acts = []\n",
    "            rets = []\n",
    "            advs = []\n",
    "            gms = []\n",
    "\n",
    "            # nData = 0\n",
    "            correct = [0. for _ in noiseAmpRatioList]\n",
    "            for tri, trAgentBatch in enumerate(trAgentLoader):\n",
    "                # nData += trAgentBatch['obs'].shape[0]\n",
    "                seqLength = trAgentBatch['obs'].shape[1]\n",
    "                obsAmp = LA.norm(trAgentBatch['obs'].view(trAgentBatch['obs'].shape[0], -1), dim=1)\n",
    "                # print('obs amp:', obsAmp)\n",
    "                obsBatchFlatten = trAgentBatch['obs'].transpose(0, 1).reshape(-1, trAgentBatch['obs'].shape[2])\n",
    "                actBatchFlatten = self.act(obsBatchFlatten)\n",
    "                actBatch = torch.reshape(actBatchFlatten, ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)\n",
    "                # actTorch = torch.reshape(torch.from_numpy(act), ([-1] + list(trAgentBatch['FGM'].shape[1:]))).to(device)\n",
    "                \n",
    "                lineBreakCount = 0\n",
    "                for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "                    pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], actBatch, trAgentBatch['label'],\\\n",
    "                                                    HARNet, noiseAmpRatio)\n",
    "                    for pred, label in zip(pred_l, label_l):\n",
    "                        correct[noiseAmpIndex] += (pred == label)\n",
    "                        # print(correct)\n",
    "                    \n",
    "                obs.append(obsBatchFlatten)\n",
    "                acts.append(actBatchFlatten)\n",
    "\n",
    "                retsBatch = torch.Tensor().to(device)\n",
    "                advsBatch = torch.Tensor().to(device)\n",
    "                gmsBatch = torch.Tensor().to(device)\n",
    "                for i, trAgentData in enumerate(trAgentBatch['obs']):\n",
    "                    ep_obs = trAgentData\n",
    "                    ep_acts = torch.squeeze(actBatch[i, :, :])\n",
    "                    ep_gms = torch.pow(gae_gamma, torch.arange(seqLength)).to(device)\n",
    "                    ep_lmbs = torch.pow(gae_lambda, torch.arange(seqLength)).to(device)\n",
    "                                        \n",
    "                    ep_costs = (-1) * torch.log(self.d(ep_obs, ep_acts)).squeeze().detach()\n",
    "                    ep_disc_costs = ep_gms * ep_costs\n",
    "                    ep_disc_rets = torch.flip(torch.flip(\\\n",
    "                        ep_disc_costs.to(device), dims=[0]).cumsum(dim=0), dims=[0])\n",
    "                    # ep_disc_rets = FloatTensor([sum(ep_disc_costs[i:]) for i in range(seqLength)]).to(device)\n",
    "                    ep_rets = ep_disc_rets / ep_gms\n",
    "                    retsBatch = torch.cat((retsBatch, ep_rets), dim=0)\n",
    "\n",
    "                    self.v.eval()\n",
    "                    curr_vals = self.v(ep_obs).detach()\n",
    "                    next_vals = torch.cat(\n",
    "                        (self.v(ep_obs)[1:], FloatTensor([[0.]]).to(device))).detach()\n",
    "                    ep_deltas = ep_costs.unsqueeze(-1) + gae_gamma * next_vals - curr_vals\n",
    "                    ep_advs = FloatTensor([\n",
    "                        ((ep_gms * ep_lmbs)[:seqLength - j].unsqueeze(-1) * ep_deltas[j:]).sum()\n",
    "                        for j in range(seqLength)]).to(device)\n",
    "\n",
    "                    advsBatch = torch.cat((advsBatch, ep_advs))\n",
    "                    gmsBatch = torch.cat((gmsBatch, ep_gms))\n",
    "                \n",
    "                rets.append(retsBatch)\n",
    "                advs.append(advsBatch)\n",
    "                gms.append(gmsBatch)\n",
    "            \n",
    "            # print('rets:', len(rets), 'advs:', len(advs), 'gms:', len(gms))\n",
    "            if normalize_advantage:\n",
    "                advsFlatten = torch.cat(advs)\n",
    "                advsFlatten = (advsFlatten - advsFlatten.mean()) / (advsFlatten.std() + 1e-8)\n",
    "                advs = torch.split(advsFlatten, [len(advsBatch) for advsBatch in advs])\n",
    "                \n",
    "            self.d.train()\n",
    "            expScores = torch.Tensor().to(device)\n",
    "            agentScores = torch.Tensor().to(device)\n",
    "            for trExpBatch in trExpLoader:\n",
    "                expObsBatch = trExpBatch['obs'].transpose(0, 1).reshape(-1, trExpBatch['obs'].shape[2])\n",
    "                expActBatch = trExpBatch['FGM'].transpose(0, 1).reshape(-1, trExpBatch['FGM'].shape[2])\n",
    "                # expScores = self.d.get_logits(expObsBatch, expActBatch)\n",
    "                expScores = torch.cat((expScores, self.d.get_logits(expObsBatch, expActBatch)), dim=0)\n",
    "                \n",
    "            for agentObsBatch, agentActsBatch in zip(obs, acts):\n",
    "                agentScores = torch.cat((agentScores, self.d.get_logits(agentObsBatch, agentActsBatch)), dim=0)\n",
    "            \n",
    "            opt_d.zero_grad()\n",
    "            lossExp = torch.nn.functional.binary_cross_entropy_with_logits(\\\n",
    "                expScores, torch.zeros_like(expScores))\n",
    "            lossAgent = torch.nn.functional.binary_cross_entropy_with_logits(\\\n",
    "                agentScores, torch.ones_like(agentScores))\n",
    "            loss = lossExp + lossAgent\n",
    "            loss.backward()\n",
    "            opt_d.step()\n",
    "\n",
    "            # print('scores: {0:.3f}, {1:.3f}'.format\\\n",
    "            #       (torch.mean(expScores).item(), torch.mean(agentScores).item()), end=' ')\n",
    "            print('scores: {0:.3f}, {1:.3f}'.format\\\n",
    "                  (torch.mean(expScores).item(), torch.mean(agentScores).item()))\n",
    "\n",
    "            \n",
    "            del expScores\n",
    "            del agentScores\n",
    "\n",
    "            self.v.train()\n",
    "            for obsBatch, actsBatch, retsBatch in zip(obs, acts, rets):\n",
    "                # print(obsBatch.shape, retsBatch.shape, advsBatch.shape, gmsBatch.shape)\n",
    "                old_params = get_flat_params(self.v).detach()\n",
    "                old_vBatch = self.v(obsBatch).detach()\n",
    "            \n",
    "                def constraint():\n",
    "                    return ((old_vBatch - self.v(obsBatch)) ** 2).mean()\n",
    "            \n",
    "                grad_diff = get_flat_grads(constraint(), self.v)\n",
    "\n",
    "                def Hv(v):\n",
    "                    hessian = get_flat_grads(torch.dot(grad_diff, v), self.v).detach()\n",
    "                    return hessian\n",
    "\n",
    "                g = get_flat_grads(\\\n",
    "                    (-1*(self.v(obsBatch).squeeze() - retsBatch) ** 2).mean(), self.v).detach()\n",
    "                s = conjugate_gradient(Hv, g).detach()\n",
    "                Hs = Hv(s).detach()\n",
    "                alpha = torch.sqrt(2 * eps / (torch.dot(s, Hs) + 1e-8)).detach()\n",
    "                new_params = old_params + alpha * s\n",
    "                # print('v:', old_params.norm().item(), alpha.item(), s.norm().item())\n",
    "                set_params(self.v, new_params)\n",
    "                # print('v:', self.v.net[0].weight[1, :2].squeeze())\n",
    "\n",
    "            print('iter final v:', self.v.net[0].weight[1, :5].squeeze().detach().cpu().numpy())\n",
    "            \n",
    "            self.pi.train()\n",
    "            for obsBatch, actsBatch, advsBatch, gmsBatch in zip(obs, acts, advs, gms):\n",
    "                old_params = get_flat_params(self.pi).detach()\n",
    "                old_distb = self.pi(obsBatch)\n",
    "\n",
    "                def L():\n",
    "                    distb = self.pi(obsBatch)\n",
    "                    return (advsBatch * torch.exp(distb.log_prob(actsBatch)\\\n",
    "                                    - old_distb.log_prob(actsBatch).detach())).mean()\n",
    "                    # return torch.distributions.kl.kl_divergence(distb, old_distb).mean()\n",
    "\n",
    "                def kld():\n",
    "                    distb = self.pi(obsBatch)\n",
    "                    old_mean = old_distb.mean.detach()\n",
    "                    old_cov = old_distb.covariance_matrix.sum(-1).detach()\n",
    "                    mean = distb.mean\n",
    "                    cov = distb.covariance_matrix.sum(-1)\n",
    "                    return (0.5) * ((old_cov / cov).sum(-1)\\\n",
    "                            + (((old_mean - mean) ** 2) / cov).sum(-1)\n",
    "                            - self.action_dim\n",
    "                            + torch.log(cov).sum(-1)\n",
    "                            - torch.log(old_cov).sum(-1)).mean()\n",
    "\n",
    "                grad_kld_old_param = get_flat_grads(kld(), self.pi)\n",
    "\n",
    "                def Hv(v):\n",
    "                    hessian = get_flat_grads(torch.dot(grad_kld_old_param, v), self.pi).detach()\n",
    "                    return hessian + cg_damping * v\n",
    "                \n",
    "                g = get_flat_grads(L(), self.pi).detach()\n",
    "                s = conjugate_gradient(Hv, g).detach()\n",
    "                Hs = Hv(s).detach()\n",
    "                new_params = rescale_and_linesearch(g, s, Hs, max_kl, L, kld, old_params, self.pi)\n",
    "\n",
    "                disc_causal_entropy = ((-1) * gmsBatch * self.pi(obsBatch).log_prob(actsBatch)).mean()\n",
    "                grad_disc_causal_entropy = get_flat_grads(disc_causal_entropy, self.pi)\n",
    "                new_params += lambda_ * grad_disc_causal_entropy\n",
    "                # print('pi:', new_params.norm().item(), lambda_, grad_disc_causal_entropy.norm().item())\n",
    "\n",
    "                set_params(self.pi, new_params)\n",
    "                # print('pi:', self.pi.net[0].weight[1, :2].squeeze())\n",
    "                # break\n",
    "            \n",
    "            print('iter final pi:', self.pi.net[0].weight[1, :5].squeeze().detach().cpu().numpy())\n",
    "\n",
    "            print('[ampRatio, Acc.]:', end=' ')\n",
    "            lineBreakCount = 0\n",
    "            ampSaveCriterion = 0.1\n",
    "            for noiseAmpIndex, noiseAmpRatio in enumerate(noiseAmpRatioList):\n",
    "                print('[{0}, {1:.3f}]'.\\\n",
    "                        format(noiseAmpRatio, correct[noiseAmpIndex]/nDataTrAgent), end=' ')\n",
    "\n",
    "                lineBreakCount += 1\n",
    "                if lineBreakCount == 4:\n",
    "                    print('')\n",
    "                    lineBreakCount = 0\n",
    "\n",
    "            compAmpRatio = np.where(np.array(noiseAmpRatioList) == ampSaveCriterion)[0][0]\n",
    "            if correct[compAmpRatio]/nDataTrAgent < bestAcc:\n",
    "                bestAcc = correct[compAmpRatio]/nDataTrAgent\n",
    "                torch.save(self.pi.state_dict(), './savedModels/GAIL/' + LSTMModelName + '_pi.cpkt')\n",
    "                torch.save(self.v.state_dict(), './savedModels/GAIL/' + LSTMModelName + '_v.cpkt')\n",
    "                torch.save(self.d.state_dict(), './savedModels/GAIL/' + LSTMModelName + '_d.cpkt')\n",
    "                print('model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----White-box attack performance (Expert)----\n",
      "[ampRatio, Acc.]: [0.0001, 0.977] [0.001, 0.974] [0.01, 0.589] [0.1, 0.165] \n",
      "----Random noise attack performance----\n",
      "[ampRatio, Acc.]: [0.0001, 0.977] [0.001, 0.977] [0.01, 0.977] [0.1, 0.817] \n",
      "nDataTrExp: 906 nDataTrAgent: 389 nDataTs: 3034\n",
      "Iter 0 scores: 0.162, 0.170\n",
      "iter final v: [-0.06313612  0.00178153 -0.03405649 -0.02652379  0.09631778]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GAIL(state_dim\u001b[38;5;241m=\u001b[39mnSubC\u001b[38;5;241m*\u001b[39mnRX, action_dim\u001b[38;5;241m=\u001b[39mnSubC\u001b[38;5;241m*\u001b[39mnRX,\\\n\u001b[1;32m      2\u001b[0m              discrete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice, train_config\u001b[38;5;241m=\u001b[39mGAILTrainConfig)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(trExpLoader.device)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHARNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrExpLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrAgentLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtsLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 297\u001b[0m, in \u001b[0;36mGAIL.train\u001b[0;34m(self, HARNet, trExpLoader, trAgentLoader, tsLoader, render)\u001b[0m\n\u001b[1;32m    294\u001b[0m     hessian \u001b[38;5;241m=\u001b[39m get_flat_grads(torch\u001b[38;5;241m.\u001b[39mdot(grad_kld_old_param, v), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hessian \u001b[38;5;241m+\u001b[39m cg_damping \u001b[38;5;241m*\u001b[39m v\n\u001b[0;32m--> 297\u001b[0m g \u001b[38;5;241m=\u001b[39m get_flat_grads(\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    298\u001b[0m s \u001b[38;5;241m=\u001b[39m conjugate_gradient(Hv, g)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    299\u001b[0m Hs \u001b[38;5;241m=\u001b[39m Hv(s)\u001b[38;5;241m.\u001b[39mdetach()\n",
      "Cell \u001b[0;32mIn[8], line 274\u001b[0m, in \u001b[0;36mGAIL.train.<locals>.L\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mL\u001b[39m():\n\u001b[0;32m--> 274\u001b[0m     distb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobsBatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (advsBatch \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(distb\u001b[38;5;241m.\u001b[39mlog_prob(actsBatch)\\\n\u001b[1;32m    276\u001b[0m                     \u001b[38;5;241m-\u001b[39m old_distb\u001b[38;5;241m.\u001b[39mlog_prob(actsBatch)\u001b[38;5;241m.\u001b[39mdetach()))\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/miniconda3/envs/wifiHAR_vel/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/24-RT_adv_HAR/GAIL/models/nets.py:45\u001b[0m, in \u001b[0;36mPolicyNetwork.forward\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m     42\u001b[0m     std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_std)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     43\u001b[0m     cov_mtx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m (std \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     distb \u001b[38;5;241m=\u001b[39m \u001b[43mMultivariateNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_mtx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distb\n",
      "File \u001b[0;32m~/miniconda3/envs/wifiHAR_vel/lib/python3.10/site-packages/torch/distributions/multivariate_normal.py:150\u001b[0m, in \u001b[0;36mMultivariateNormal.__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m=\u001b[39m loc\u001b[38;5;241m.\u001b[39mexpand(batch_shape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m    149\u001b[0m event_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale_tril \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbroadcasted_scale_tril \u001b[38;5;241m=\u001b[39m scale_tril\n",
      "File \u001b[0;32m~/miniconda3/envs/wifiHAR_vel/lib/python3.10/site-packages/torch/distributions/distribution.py:61\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[1;32m     60\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m---> 61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GAIL(state_dim=nSubC*nRX, action_dim=nSubC*nRX,\\\n",
    "             discrete=False, device=device, train_config=GAILTrainConfig)\n",
    "# print(trExpLoader.device)\n",
    "model.train(HARNet, trExpLoader, trAgentLoader, tsLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-05, 0.977] [0.0001, 0.977] [0.0005, 0.977] [0.001, 0.977] [0.002, 0.977] [0.005, 0.977] [0.01, 0.977] [0.02, 0.956] [0.05, 0.668] [0.075, 0.571] [0.1, 0.504] [0.2, 0.432] [0.5, 0.362] "
     ]
    }
   ],
   "source": [
    "# HARNet = LSTMNet(nClasses=len(activities), input_size=nSubC*nRX, bidirectional=bidirectional,\\\n",
    "#                  hidden_size=nHidden, num_layers=nLayer, seq_length=winLen//2, device=device)\n",
    "\n",
    "pi = PolicyNetwork(nSubC*nRX, nSubC*nRX, False, device)\n",
    "v = ValueNetwork(nSubC*nRX, device)\n",
    "d = Discriminator(nSubC*nRX, nSubC*nRX, False, device)\n",
    "\n",
    "GAILConfigName = 'GAILConfig01_LRe-3'\n",
    "\n",
    "pi.load_state_dict(torch.load('./savedModels/GAIL/' + LSTMModelName + '_' + GAILConfigName + '_pi.cpkt'))\n",
    "v.load_state_dict(torch.load('./savedModels/GAIL/' + LSTMModelName + '_' + GAILConfigName + '_v.cpkt'))\n",
    "d.load_state_dict(torch.load('./savedModels/GAIL/' + LSTMModelName + '_' + GAILConfigName + '_d.cpkt'))\n",
    "\n",
    "GAILEvalModel = GAIL(state_dim=nSubC*nRX, action_dim=nSubC*nRX,\\\n",
    "             discrete=False, device=device, train_config=GAILTrainConfig)\n",
    "\n",
    "GAILEvalModel.eval(trAgentLoader, pi, v, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-05, 0.977] [0.0001, 0.977] [0.0005, 0.977] [0.001, 0.974] \n",
      "[0.002, 0.969] [0.005, 0.835] [0.01, 0.589] [0.02, 0.362] \n",
      "[0.05, 0.193] [0.075, 0.190] [0.1, 0.165] [0.2, 0.129] \n",
      "[0.5, 0.069] \n",
      "[1e-05, 0.977] [0.0001, 0.977] [0.0005, 0.977] [0.001, 0.977] \n",
      "[0.002, 0.977] [0.005, 0.977] [0.01, 0.977] [0.02, 0.977] \n",
      "[0.05, 0.972] [0.075, 0.920] [0.1, 0.817] [0.2, 0.496] \n",
      "[0.5, 0.337] "
     ]
    }
   ],
   "source": [
    "nDataTrAgent = 0\n",
    "for trAgentBatch in trAgentLoader:\n",
    "    nDataTrAgent += trAgentBatch['obs'].shape[0]\n",
    "noiseAmpRatioList = [1e-5, 1e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 7.5e-2, 0.1, 0.2, 0.5]\n",
    "\n",
    "lineBreakCount = 0\n",
    "for noiseAmpRatio in noiseAmpRatioList:\n",
    "    correct = 0.\n",
    "    \n",
    "    for trAgentBatch in trAgentLoader:\n",
    "        pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], trAgentBatch['FGM'], trAgentBatch['label'],\\\n",
    "                                        HARNet, noiseAmpRatio)\n",
    "        for pred, label in zip(pred_l, label_l):\n",
    "            correct += (pred == label)\n",
    "    print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nDataTrAgent), end=' ')\n",
    "    lineBreakCount += 1\n",
    "    if lineBreakCount == 4:\n",
    "        print('')\n",
    "        lineBreakCount = 0\n",
    "\n",
    "if lineBreakCount != 0:\n",
    "    print('')\n",
    "lineBreakCount = 0\n",
    "for noiseAmpRatio in noiseAmpRatioList:\n",
    "    correct = 0.\n",
    "    for trAgentBatch in trAgentLoader:\n",
    "        noiseBatch = torch.randn(trAgentBatch['obs'].shape).to(device)\n",
    "        pred_l,label_l = getPredsGAIL(trAgentBatch['obs'], noiseBatch, trAgentBatch['label'],\\\n",
    "                                        HARNet, noiseAmpRatio)\n",
    "        for pred, label in zip(pred_l, label_l):\n",
    "            correct += (pred == label)\n",
    "        # accuracyList.append(correct/nData)\n",
    "    print('[{0}, {1:.3f}]'.format(noiseAmpRatio, correct/nDataTrAgent), end=' ')\n",
    "    lineBreakCount += 1\n",
    "    if lineBreakCount == 4:\n",
    "        print('')\n",
    "        lineBreakCount = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wifiHAR_vel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
